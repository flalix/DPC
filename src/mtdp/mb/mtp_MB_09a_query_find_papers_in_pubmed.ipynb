{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.12.0\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os, sys, pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.width', 100)\n",
    "pd.set_option('max_colwidth', 80)\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_context(\"notebook\", font_scale=1.4)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "%matplotlib inline\n",
    "\n",
    "sys.path.insert(1, '../src/')\n",
    "\n",
    "from Basic import *\n",
    "from entrez_conversion import *\n",
    "from pubmed_lib import *\n",
    "from gemini_lib import *\n",
    "from biopax_lib import *\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "email = \"flalix@gmail.com\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pubmed search\n",
    "\n",
    "#### scipy corpus data\n",
    "\n",
    "https://allenai.github.io/scispacy/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G/P LFC cutoffs: lfc=1.000; fdr=0.050\n",
      "Pathway cutoffs: pval=0.050; fdr=0.050; num of genes=3\n"
     ]
    }
   ],
   "source": [
    "root_chibe = \"../../chibe/\"\n",
    "root_colab = '../../colaboracoes/'\n",
    "root0       = '../../colaboracoes/covid/sonia_andrade/taubate/proteomics_202205/'\n",
    "\n",
    "project = 'Taubate COVID-19'\n",
    "s_project = 'taubate_covid19'\n",
    "\n",
    "gene_protein = 'protein'\n",
    "s_omics = 'proteomics'\n",
    "\n",
    "has_age = True\n",
    "has_gender = True\n",
    "\n",
    "want_normalized = False\n",
    "exp_normalization='quantile_norm' if want_normalized else None\n",
    "normalization = 'not_normalized' if exp_normalization is None else exp_normalization\n",
    "\n",
    "abs_lfc_cutoff_inf = 0.40\n",
    "s_pathw_enrichm_method = 'enricher'\n",
    "num_min_degs_for_ptw_enr=3\n",
    "tolerance_pathway_index = 0.15\n",
    "\n",
    "case_list = ['g2a_male', 'g2a_female', \n",
    "             'g2b_male', 'g2b_female', \n",
    "             'g3_male_adult',   'g3_male_elder',\n",
    "             'g3_female_adult', 'g3_female_elder']\n",
    "\n",
    "cfg = Config(project, s_project, case_list, root0)\n",
    "\n",
    "case = case_list[0]\n",
    "\n",
    "n_genes_annot_ptw, n_degs, n_degs_in_ptw, n_degs_not_in_ptw, degs_in_all_ratio = -1,-1,-1,-1,-1\n",
    "abs_lfc_cutoff, fdr_lfc_cutoff, n_degs, n_degs_up, n_degs_dw = cfg.get_best_lfc_cutoff(case, 'not_normalized')\n",
    "\n",
    "pval_pathway_cutoff = 0.05\n",
    "fdr_pathway_cutoff = .05\n",
    "num_of_genes_cutoff = 3\n",
    "\n",
    "print(f\"G/P LFC cutoffs: lfc={abs_lfc_cutoff:.3f}; fdr={fdr_lfc_cutoff:.3f}\")\n",
    "print(f\"Pathway cutoffs: pval={pval_pathway_cutoff:.3f}; fdr={fdr_pathway_cutoff:.3f}; num of genes={num_of_genes_cutoff}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start opening tables ....\n",
      "Building synonym dictionary ...\n",
      "\n",
      "\n",
      "Echo Parameters:\n",
      "For case 'g3_male_elder', there are 140/140 DAPs/DAPs with ensembl_id\n",
      "DAP's cutoffs: abs(LFC)=0.600; FDR=0.400\n",
      "\t140/140 DAPs/ensembl.\n",
      "\t\tUp 40/40 DAPs/ensembl.\n",
      "\t\tDw 100/100 DAPs/ensembl.\n",
      "\n",
      "Found 60 (best=60) pathways for geneset num=0 'Reactome_2022'\n",
      "Pathway cutoffs p-value=0.050 fdr=0.050 min genes=3\n",
      "DAPs found in enriched pathways:\n",
      "\tThere are 140 DAPs found in pathways\n",
      "\t105 (best=105) DAPs in pathways and 35/35 DAPs/ensembl not in pathways\n",
      "\n",
      "\t34 DAPs ensembl Up in pathways\n",
      "\t6 DAPs Up ensembl not in pathways\n",
      "\n",
      "\t71 DAPs ensembl Dw in pathways\n",
      "\t29 DAPs Dw ensembl not in pathways\n"
     ]
    }
   ],
   "source": [
    "pathway_name_id = 'Hemostasis - R-HSA-109582'\n",
    "pathway_name_id = 'Regulation Of IGF Transport And Uptake By IGFBPs - R-HSA-381426'\n",
    "pathway_name_id = 'Platelet degranulate - R-HSA-114608'\n",
    "pathway_name_id = 'Platelet Activation, Signaling And Aggregation - R-HSA-76002'\n",
    "pathway_name_id = 'Integrin Cell Surface Interactions - R-HSA-216083'\n",
    "pathway_name_id = 'Neutrophil Degranulation - R-HSA-6798695'\n",
    "pathway_name_id = 'Regulation of Complement cascade - R-HSA-977606'\n",
    "pathway_name_id = 'Response To Elevated Platelet Cytosolic Ca2+ - R-HSA-76005'\n",
    "\n",
    "bpx = Biopax(gene_protein, s_omics, project, s_project, root0,\n",
    "             case_list, has_age, has_gender, clone_objects=False,\n",
    "             exp_normalization=exp_normalization, geneset_num=0, \n",
    "             num_min_degs_for_ptw_enr=num_min_degs_for_ptw_enr, \n",
    "             tolerance_pathway_index=tolerance_pathway_index, \n",
    "             s_pathw_enrichm_method = s_pathw_enrichm_method)\n",
    "\n",
    "case = case_list[5]\n",
    "\n",
    "bpx.cfg.set_default_best_lfc_cutoff(normalization, abs_lfc_cutoff=1, fdr_lfc_cutoff=0.05)\n",
    "ret, degs, degs_ensembl, dfdegs = bpx.open_case(case, verbose=False)\n",
    "print(\"\\nEcho Parameters:\")\n",
    "bpx.echo_parameters()\n",
    "\n",
    "geneset_num = bpx.geneset_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "/media/flalix/d2f268d1-512d-499f-b3b3-6dad7d3fdd25/anaconda3/envs/pytorch_env/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " COVID-19 is the disease caused by the virus SARS-CoV-2. When the virus enters your body, it infects cells, primarily in the respiratory system.\n"
     ]
    }
   ],
   "source": [
    "API_KEY='AIzaSyA1ZXcSe6NP5jiIw93sUpZYb8RKK1PgYDE'\n",
    "disease='COVID-19'\n",
    "context_disease=\"COVID-19 is the disease caused by the virus SARS-CoV-2. When the virus enters your body, it infects cells, primarily in the respiratory system.\"\n",
    "\n",
    "n_sentences=5\n",
    "chosen_model_list=[1,3]\n",
    "i_dfp_list=[0,1,2,3]\n",
    "\n",
    "gem=Gemini(bpx=bpx, disease=disease, context_disease=context_disease, n_sentences=n_sentences, API_KEY=API_KEY, \n",
    "             root0=root0, i_dfp_list=i_dfp_list, chosen_model_list=chosen_model_list)\n",
    "print(\"\\n\",context_disease)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taubate_covid19 2019/10/01 2030/12/31\n",
      "Start opening tables ....\n",
      "Building synonym dictionary ...\n",
      "\n",
      "File ../src/down_pdf_pmid.sh exists True\n"
     ]
    }
   ],
   "source": [
    "prefix = s_project\n",
    "inidate=\"2019/10/01\"\n",
    "enddate=\"2030/12/31\"\n",
    "\n",
    "print(prefix, inidate, enddate)\n",
    "\n",
    "force_query = False\n",
    "verbose_query=False\n",
    "\n",
    "sleep_entrez = [30, 90, 300]; retmax=100000,\n",
    "\n",
    "''' CAP: community-acquired pneumonia\n",
    "    MV: mechanical ventilator\n",
    "'''\n",
    "remove_synonym_list =  ['CAP', 'MV', 'MDB']\n",
    "\n",
    "pub = Pubmed(bpx, gem, email, prefix, inidate, enddate, \n",
    "             root0, remove_synonym_list=remove_synonym_list, \n",
    "             sleep_entrez = [5, 7, 10], retmax=100000,  \n",
    "             try_all_text=True, text_quote='',\n",
    "             root_colab=root_colab, dec_ncpus=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PubMed Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test=False\n",
    "force=False\n",
    "verbose=False\n",
    "\n",
    "for case in case_list:\n",
    "    for with_gender in [True, False]:\n",
    "        print(\">>>\",  case, with_gender)\n",
    "\n",
    "        terms_not_param = ['NOT', 'MERS', 'SARS-CoV-1']\n",
    "        terms1_param = [\"OR\", 'COVID', 'SARS-CoV-2']\n",
    "        connective_param = 'AND'\n",
    "\n",
    "    \n",
    "        _ = pub.run_case_pathway_pubmed_search(case=case, with_gender=with_gender, terms1=terms1_param, \n",
    "                                               terms_not=terms_not_param, connective=connective_param, \n",
    "                                               test=test, force=force, verbose=verbose)\n",
    "\n",
    "    print(\"\")\n",
    "print(\"-------------- end --------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_list = ['elder']\n",
    "not_list + ['young', 'child', 'neonat', 'newborn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms_and_or, terms_not2 = pub.case_to_terms()\n",
    "terms_not2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose=False\n",
    "\n",
    "terms_not_param = ['NOT', 'MERS', 'SARS-CoV-1']\n",
    "terms1_param = [\"OR\", 'COVID', 'SARS-CoV-2']\n",
    "connective_param = 'AND'\n",
    "\n",
    "with_gender = True\n",
    "\n",
    "i = 0\n",
    "case = case_list[i]\n",
    "print(\">>>\", case)\n",
    "\n",
    "df_case = pub.run_case_pathway_pubmed_search(case=case, with_gender=with_gender, terms1=terms1_param, \n",
    "                                             terms_not=terms_not_param, connective=connective_param, \n",
    "                                             inidate=inidate, enddate=enddate,\n",
    "                                             test=False, save_file=False, force=False, verbose=verbose)\n",
    "if df_case is None:\n",
    "    df_case = pd.DataFrame()\n",
    "print(len(df_case))\n",
    "df_case.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pub.df_summ_pmid.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pub.df_summ_pathway.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_case.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PubMed Search Old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathway_name_id_list = [['Hemostasis - R-HSA-109582', 'Platelet degranulate - R-HSA-114608', 'Platelet Activation, Signaling And Aggregation - R-HSA-76002',\n",
    "                         'Response To Elevated Platelet Cytosolic Ca2+ - R-HSA-76005'], ['Regulation Of IGF Transport And Uptake By IGFBPs - R-HSA-381426'],\n",
    "                        ['Integrin Cell Surface Interactions - R-HSA-216083'], ['Neutrophil Degranulation - R-HSA-6798695'],\n",
    "                        ['Regulation of Complement cascade - R-HSA-977606']]\n",
    "\n",
    "pathway_concept_name_list = ['Hemostasis', 'IGF Transport', 'Integrins', 'Neutrophils', 'thrombosis', 'vaccination']\n",
    "\n",
    "pathway_concept_list = [['hemost'], ['IGF', 'Insulin-Like Growth Factor'], ['integrin'], ['neutrophil', 'nets'], ['thrombo', 'clot'], ['vaccin']]\n",
    "\n",
    "len(pathway_concept_name_list), len(pathway_concept_list), pathway_concept_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathway_concept_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connective = \"AND\"\n",
    "choices = ['hemostasis', 'platelet', 'inflammation', 'complement', 'lung', 'cardio',\n",
    "           'gut', 'elder', 'obese',  'brain', 'antibody', 'mab', 'cellular', \n",
    "           'therapy', 'bad_therapy', 'death', 'sequel', 'severe', 'moderate', 'biomarker', 'omics']\n",
    "\n",
    "''' CAP: community-acquired pneumonia\n",
    "    MV: mechanical ventilator\n",
    "'''\n",
    "remove_synonyms =  ['CAP', 'MV', 'MDB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_choice = {}\n",
    "\n",
    "terms_not = ['NOT', 'MERS', 'SARS-CoV-1']\n",
    "terms1 = [\"OR\", 'COVID', 'SARS-CoV-2']\n",
    "\n",
    "# choices = ['hemostasis', 'platelet', 'inflammation', 'death', 'sequel']\n",
    "\n",
    "for choice in choices:\n",
    "    \n",
    "    if choice == 'hemostasis':\n",
    "        dic_choice[choice] = {}\n",
    "        dic2 = dic_choice[choice]\n",
    "        \n",
    "        dic2['terms1'] = terms1\n",
    "        dic2['terms2'] = ['OR', 'hemostasis', 'haemostasis']\n",
    "        dic2['terms_not'] = terms_not\n",
    "        \n",
    "    elif choice == 'platelet':\n",
    "        dic_choice[choice] = {}\n",
    "        dic2 = dic_choice[choice]\n",
    "        \n",
    "        dic2['terms1'] = terms1\n",
    "        dic2['terms2'] = ['OR', 'platelet']\n",
    "        dic2['terms_not'] = terms_not\n",
    "        \n",
    "    elif choice == 'inflammation':\n",
    "        dic_choice[choice] = {}\n",
    "        dic2 = dic_choice[choice]\n",
    "        \n",
    "        dic2['terms1'] = terms1\n",
    "        dic2['terms2'] = ['OR', 'inflammation', 'innate']\n",
    "        dic2['terms_not'] = terms_not + ['complement']\n",
    "\n",
    "    elif choice == 'complement':\n",
    "        dic_choice[choice] = {}\n",
    "        dic2 = dic_choice[choice]\n",
    "        \n",
    "        dic2['terms1'] = terms1\n",
    "        dic2['terms2'] = ['OR', 'complement']\n",
    "        dic2['terms_not'] = terms_not\n",
    "\n",
    "    elif choice == 'lung':\n",
    "        dic_choice[choice] = {}\n",
    "        dic2 = dic_choice[choice]\n",
    "        \n",
    "        dic2['terms1'] = terms1\n",
    "        dic2['terms2'] = ['OR', 'lung', 'alveolus', 'trachea', 'bronch']\n",
    "        dic2['terms_not'] = terms_not\n",
    "        \n",
    "    elif choice == 'cardio':\n",
    "        dic_choice[choice] = {}\n",
    "        dic2 = dic_choice[choice]\n",
    "        \n",
    "        dic2['terms1'] = terms1\n",
    "        dic2['terms2'] = ['OR', 'cardi', 'miocardi']\n",
    "        dic2['terms_not'] = terms_not\n",
    "\n",
    "    elif choice == 'gut':\n",
    "        dic_choice[choice] = {}\n",
    "        dic2 = dic_choice[choice]\n",
    "        \n",
    "        dic2['terms1'] = terms1\n",
    "        dic2['terms2'] = ['OR', 'gut']\n",
    "        dic2['terms_not'] = terms_not\n",
    "        \n",
    "    elif choice == 'elder':\n",
    "        dic_choice[choice] = {}\n",
    "        dic2 = dic_choice[choice]\n",
    "        dic2['terms1'] = terms1\n",
    "        dic2['terms2'] = ['OR', 'elder']\n",
    "        dic2['terms_not'] = terms_not\n",
    "        \n",
    "    elif choice == 'obese':\n",
    "        dic_choice[choice] = {}\n",
    "        dic2 = dic_choice[choice]\n",
    "        dic2['terms1'] = terms1\n",
    "        dic2['terms2'] = ['OR', 'obese']\n",
    "\n",
    "        dic2['terms_not'] = terms_not\n",
    "        \n",
    "    elif choice == 'brain':\n",
    "        dic_choice[choice] = {}\n",
    "        dic2 = dic_choice[choice]\n",
    "        dic2['terms1'] = terms1\n",
    "        dic2['terms2'] = ['OR', 'brain', 'nervous system']\n",
    "        dic2['terms_not'] = terms_not\n",
    "\n",
    "    elif choice == 'antibody':\n",
    "        dic_choice[choice] = {}\n",
    "        dic2 = dic_choice[choice]\n",
    "        dic2['terms1'] = terms1\n",
    "        dic2['terms2'] = ['OR', 'antibody', 'b-cell', 'innactivation', 'humoral']\n",
    "        dic2['terms_not'] = terms_not + ['monoclonal antibody', 'MAB', 'cellular response', 't-cell']\n",
    "\n",
    "    elif choice == 'mab':\n",
    "        dic_choice[choice] = {}\n",
    "        dic2 = dic_choice[choice]\n",
    "        dic2['terms1'] = terms1\n",
    "        dic2['terms2'] = ['OR', 'monoclonal antibody', 'MAB']\n",
    "        dic2['terms_not'] = terms_not + ['cellular response', 't-cell']\n",
    "\n",
    "    elif choice == 'cellular':\n",
    "        dic_choice[choice] = {}\n",
    "        dic2 = dic_choice[choice]\n",
    "        dic2['terms1'] = terms1\n",
    "        dic2['terms2'] = ['OR', 'cellular response', 't-cell']\n",
    "        dic2['terms_not'] = terms_not + ['antibody', 'humoral']\n",
    "        \n",
    "    elif choice == 'death':\n",
    "        dic_choice[choice] = {}\n",
    "        dic2 = dic_choice[choice]\n",
    "        dic2['terms1'] = terms1\n",
    "        dic2['terms2'] = ['OR', 'death', 'necrosis', 'apoptosis', 'mortal', 'fatal']\n",
    "        dic2['terms_not'] = terms_not\n",
    "        \n",
    "    elif choice == 'sequel':\n",
    "        dic_choice[choice] = {}\n",
    "        dic2 = dic_choice[choice]\n",
    "        dic2['terms1'] = terms1\n",
    "        dic2['terms2'] = ['OR', 'sequel', 'disorder']\n",
    "        dic2['terms_not'] = terms_not\n",
    "        \n",
    "    elif choice == 'severe':\n",
    "        dic_choice[choice] = {}\n",
    "        dic2 = dic_choice[choice]\n",
    "        dic2['terms1'] = terms1\n",
    "        dic2['terms2'] = ['OR', 'severe']\n",
    "        dic2['terms_not'] = terms_not\n",
    "        \n",
    "    elif choice == 'moderate':\n",
    "        dic_choice[choice] = {}\n",
    "        dic2 = dic_choice[choice]\n",
    "        dic2['terms1'] = terms1\n",
    "        dic2['terms2'] = ['OR', 'moderate', 'mild']\n",
    "        dic2['terms_not'] = terms_not\n",
    "\n",
    "    elif choice == 'therapy':\n",
    "        dic_choice[choice] = {}\n",
    "        dic2 = dic_choice[choice]\n",
    "        dic2['terms1'] = terms1\n",
    "        dic2['terms2'] = ['OR', 'therapy', 'treatment']\n",
    "        dic2['terms_not'] = terms_not + ['ivermectin', 'chloroquine']\n",
    "      \n",
    "    elif choice == 'bad_therapy':\n",
    "        dic_choice[choice] = {}\n",
    "        dic2 = dic_choice[choice]\n",
    "        dic2['terms1'] = terms1\n",
    "        dic2['terms2'] = ['OR', 'ivermectin', 'chloroquine']\n",
    "        dic2['terms_not'] = terms_not\n",
    "      \n",
    "    elif choice == 'biomarker':\n",
    "        dic_choice[choice] = {}\n",
    "        dic2 = dic_choice[choice]\n",
    "        dic2['terms1'] = terms1\n",
    "        dic2['terms2'] = ['biomarker']\n",
    "        dic2['terms_not'] = terms_not\n",
    "      \n",
    "    elif choice == 'omics':\n",
    "        dic_choice[choice] = {}\n",
    "        dic2 = dic_choice[choice]\n",
    "        dic2['terms1'] = terms1\n",
    "        dic2['terms2'] = ['OR', 'signature', 'transcriptom', 'proteom', 'epigenom']\n",
    "        dic2['terms_not'] = terms_not\n",
    "        \n",
    "    else:\n",
    "        print(\"Which choice???\", choice)\n",
    "        continue        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(dic_choice.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inidate, enddate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=True\n",
    "save_file=True\n",
    "force=True\n",
    "verbose=False\n",
    "\n",
    "'''\n",
    "old ...\n",
    "\n",
    "df_all = pub.run_choice_concept_comparisons(dic_choice, pathway_concept_name_list, pathway_concept_list,\n",
    "                                            connective, inidate=inidate, enddate=enddate,\n",
    "                                            test=test, save_file=save_file, force=force, verbose=verbose)\n",
    "print(\"-------------- end --------------\")\n",
    "len(df_all)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Development & tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['concept', 'choice', 'pmid', 'pub_date', 'title',\n",
    "       'keywords', 'abstract', 'abreviation', 'authors', 'created_date', 'doc_type', 'docid',\n",
    "       'journalTitle', 'language', 'cases', 'case_comparisons', 'terms', 'dates']\n",
    "df_all = df_all[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listax = [x for x in df_all.pmid if not isint(x)]\n",
    "listax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdwritecsv(df_all, 'df_all.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pdreadcsv('df_all.tsv')\n",
    "print(len(df3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.pmid = df3.pmid.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = df_all[ ~df_all.pmid.isna()]\n",
    "df_all = df_all[ ~df_all.pmid.isna()]\n",
    "df_all.pmid = df_all.pmid.astype(int)\n",
    "df_all = df_all.sort_values('pmid')\n",
    "\n",
    "len(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pmid in df_all.pmid:\n",
    "    if not isinstance(pmid, int):\n",
    "        print(pmid, type(pmid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "previous_pmid = '';  new_row = None\n",
    "df_list = []\n",
    "for i in range(len(df_all)):\n",
    "    row = df_all.iloc[i].copy()\n",
    "    pmid = row.pmid\n",
    "\n",
    "    if previous_pmid != pmid:\n",
    "        if new_row is not None:\n",
    "            df_list.append(pd.DataFrame(new_row).T)\n",
    "\n",
    "        previous_pmid = pmid\n",
    "        new_row = row\n",
    "\n",
    "        choice = row.choice\n",
    "        if isinstance(choice, str):\n",
    "            choice = eval(choice) if choice.startswith('[') else [choice]\n",
    "\n",
    "        concept = row.concept\n",
    "        if isinstance(concept, str):\n",
    "            concept = eval(concept) if concept.startswith('[') else [concept]\n",
    "\n",
    "    else:\n",
    "        choice2 = row.choice\n",
    "        if isinstance(choice2, str):\n",
    "            choice2 = eval(choice2) if choice2.startswith('[') else [choice2]\n",
    "\n",
    "        concept2 = row.concept\n",
    "        if isinstance(concept2, str):\n",
    "            concept2 = eval(concept2) if concept2.startswith('[') else [concept2]\n",
    "\n",
    "        if choice == []:\n",
    "            choice = choice2\n",
    "        elif choice2 == []:\n",
    "            pass\n",
    "        else:\n",
    "            choice += choice2\n",
    "\n",
    "        if concept == concept2 or concept2 == []:\n",
    "            pass\n",
    "        elif concept == []:\n",
    "            concept = concept2\n",
    "        else:\n",
    "            concept += concept2\n",
    "\n",
    "        new_row.choice = choice\n",
    "        new_row.concept = concept\n",
    "        new_row.concept_list = None\n",
    "\n",
    "\n",
    "df_list.append(pd.DataFrame(new_row).T)\n",
    "dfa = pd.concat(df_list)\n",
    "\n",
    "dfa['concept'] = [\";\".join(np.unique(x)) for x in dfa.concept]\n",
    "dfa['choice']  = [\";\".join(np.unique(x)) for x in dfa.choice]\n",
    "\n",
    "dfa = dfa.sort_values(['concept', 'choice', 'pub_date', 'pmid'], ascending=[True, True, False, False])\n",
    "print(\"Total found: %d articles\"%(len(dfa)))\n",
    "fname = pub.fname_nosymb0%(pub.prefix, pub.s_abstract)\n",
    "fname = title_replace(fname)\n",
    "ret = pdwritecsv(dfa, fname, pub.root_pubmed, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms = [  ['AND'],\n",
    "         [],\n",
    "           ['AND', 'AAAA',     'BBBBB'],\n",
    "           ['OR',       'CCCC', 'CCCCS'],\n",
    "           ['AND',      'VVVV', 'UUUU'],\n",
    "           ['AND NOT ', 'CANCER', 'DIABETIS']]\n",
    "    \n",
    "term_genes = []\n",
    "\n",
    "pub.terms = terms\n",
    "pub.term_genes = term_genes\n",
    "\n",
    "pub.build_query(terms, term_genes, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose_query=False; force_query = False\n",
    "\n",
    "for choice in choices:\n",
    "    dic2 = dic_choice[choice]\n",
    "    \n",
    "    terms1 = dic2['terms1'] \n",
    "    terms2 = dic2['terms2'] \n",
    "    terms_not = dic2['terms_not'] \n",
    "    \n",
    "    print(choice)\n",
    "    print('\\t', terms1, terms2, terms_not,'\\n')\n",
    "    \n",
    "    #----------------------------------------------------------\n",
    "    pub = Pubmed(email, prefix, root0, sleep_entrez=sleep_entrez, \n",
    "                 force_query=force_query, verbose_query=verbose_query, retmax=retmax)\n",
    "    pub.biobert_init(root_biobert = root_biobert)\n",
    "\n",
    "\n",
    "    df_choi = pub.run_big_comparisons(bpx, choice, pathway_concept_name_list, pathway_concept_list,\n",
    "                                      connective=connective, terms1=terms1, terms2=terms2,\n",
    "                                      terms_not=terms_not, remove_synonyms=remove_synonyms,\n",
    "                                      inidate=inidate, enddate=enddate, \n",
    "                                      only_title_abstract=True, text_quote='', save_file=True,\n",
    "                                      force=force, verbose=verbose)\n",
    "    \n",
    "    df_all_list.append(df_choi)\n",
    "\n",
    "\n",
    "print(\"\\n--------------- final end -------------------\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.concat(df_all_list)\n",
    "df_all = df_all.sort_values('pmid')\n",
    "print(len(df_all))\n",
    "\n",
    "previous_pmid = ''\n",
    "new_row = None\n",
    "df_list = []\n",
    "\n",
    "for i in range(len(df_all)):\n",
    "    row = df_all.iloc[i].copy()\n",
    "    pmid = row.pmid\n",
    "\n",
    "    if previous_pmid != pmid:\n",
    "        if new_row is not None:\n",
    "            df_list.append(pd.DataFrame(new_row).T)\n",
    "            \n",
    "        previous_pmid = pmid\n",
    "        new_row = row\n",
    "        choice  = [] if row.choice  is None or row.choice  == [] else [row.choice]\n",
    "        concept = [] if row.concept is None or row.concept == '' else [row.concept]\n",
    "    else:\n",
    "        choice2  = [] if row.choice  is None or row.choice  == [] else [row.choice]\n",
    "        concept2 = [] if row.concept is None or row.concept == '' else [row.concept]\n",
    "        \n",
    "        if choice == []:\n",
    "            choice = choice2\n",
    "        elif choice2 == []:\n",
    "            pass\n",
    "        else:\n",
    "            choice += choice2\n",
    "            \n",
    "        if concept == concept2 or concept2 == []:\n",
    "            pass\n",
    "        elif concept == []:\n",
    "            concept = concept2\n",
    "        else:\n",
    "            concept == concept2\n",
    "            \n",
    "        new_row.choice = choice\n",
    "        new_row.concept = concept\n",
    "        new_row.concept_list = None\n",
    "        \n",
    "        \n",
    "df_list.append(pd.DataFrame(new_row).T)\n",
    "print(len(df_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfa = pd.concat(df_list)\n",
    "print(len(dfa))\n",
    "dfa.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfa['concept'] = [\";\".join(list(np.unique(x))) for x in dfa.concept]\n",
    "dfa['choice']  = [\";\".join(list(np.unique(x))) for x in dfa.choice]\n",
    "\n",
    "dfa = dfa.sort_values(['concept', 'choice', 'pub_date', 'pmid'], ascending=[True, True, False, False])\n",
    "print(\"Total found: %d articles\"%(len(dfa)))\n",
    "fname = \"pubmed_summ_%s_no_symbol_%s.tsv\"%(pub.prefix, pub.s_abstract)\n",
    "ret = pdwritecsv(dfa, fname, pub.root_pubmed, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
