{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from platform import python_version\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13 DPC\n",
    "### All cases and pathways (G0, G1, G2, and G3)\n",
    "#### Calc hard-reproducibility\n",
    "#### Calc soft-reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gemini API\n",
    "\n",
    "https://ai.google.dev/gemini-api/docs\n",
    "\n",
    "### API key - Free of charge\n",
    "\n",
    "https://aistudio.google.com/app/apikey\n",
    "\n",
    "### Google Enable API\n",
    "\n",
    "  - You are about to enable 'Generative Language API'.\n",
    "\n",
    "https://ai.google.dev/gemini-api/docs/oauth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.width', 100)\n",
    "pd.set_option('max_colwidth', 80)\n",
    "import yaml\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_context(\"notebook\", font_scale=1.4)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "%matplotlib inline\n",
    "\n",
    "sys.path.insert(1, '../src/')\n",
    "\n",
    "from Basic import *\n",
    "from entrez_conversion import *\n",
    "from biopax_lib import *\n",
    "from gemini_lib import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "# display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "display(HTML(\"<style>:root { --jp-notebook-max-width: 100% !important; }</style>\"))\n",
    "\n",
    "email = \"flalix@gmail.com\"\n",
    "\n",
    "# !pip3 install pyyaml\n",
    "with open('params.yml', 'r') as file:\n",
    "    dic_yml = yaml.safe_load(file)\n",
    "\n",
    "# print(dic_yml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_chibe = dic_yml['root_chibe']\n",
    "root_colab = dic_yml['root_colab']\n",
    "root0 = dic_yml['root0']\n",
    "\n",
    "project = dic_yml['project']\n",
    "s_project = dic_yml['s_project']\n",
    "\n",
    "gene_protein = dic_yml['gene_protein']\n",
    "s_omics = dic_yml['s_omics']\n",
    "\n",
    "has_age = dic_yml['has_age']\n",
    "has_gender = dic_yml['has_gender']\n",
    "\n",
    "want_normalized = dic_yml['want_normalized']\n",
    "\n",
    "abs_lfc_cutoff_inf = dic_yml['abs_lfc_cutoff_inf']\n",
    "s_pathw_enrichm_method = dic_yml['s_pathw_enrichm_method']\n",
    "num_min_degs_for_ptw_enr = dic_yml['num_min_degs_for_ptw_enr']\n",
    "\n",
    "tolerance_pathway_index = dic_yml['tolerance_pathway_index']\n",
    "type_sat_ptw_index = dic_yml['type_sat_ptw_index']\n",
    "saturation_lfc_index = dic_yml['saturation_lfc_index']\n",
    "chosen_model_sampling = dic_yml['chosen_model_sampling']\n",
    "\n",
    "case_list = dic_yml['case_list']\n",
    "case_sel_list = dic_yml['case_sel_list']\n",
    "s_len_case = dic_yml['s_len_case']\n",
    "\n",
    "pval_pathway_cutoff = dic_yml['pval_pathway_cutoff']\n",
    "fdr_pathway_cutoff = dic_yml['fdr_pathway_cutoff']\n",
    "num_of_genes_cutoff = dic_yml['num_of_genes_cutoff']\n",
    "\n",
    "run_list = dic_yml['run_list']\n",
    "chosen_model_list = dic_yml['chosen_model_list']\n",
    "i_dfp_list = dic_yml['i_dfp_list']\n",
    "\n",
    "exp_normalization='quantile_norm' if want_normalized else None\n",
    "normalization='not_normalized' if exp_normalization is None else exp_normalization\n",
    "\n",
    "cfg = Config(project, s_project, case_list, root0)\n",
    "\n",
    "case = case_list[0]\n",
    "\n",
    "n_genes_annot_ptw, n_degs, n_degs_in_ptw, n_degs_not_in_ptw, degs_in_all_ratio = -1,-1,-1,-1,-1\n",
    "abs_lfc_cutoff, fdr_lfc_cutoff, n_degs, n_degs_up, n_degs_dw = cfg.get_best_lfc_cutoff(case, 'not_normalized')\n",
    "\n",
    "print(f\"G/P LFC cutoffs: lfc={abs_lfc_cutoff:.3f}; fdr={fdr_lfc_cutoff:.3f}\")\n",
    "print(f\"Pathway cutoffs: pval={pval_pathway_cutoff:.3f}; fdr={fdr_pathway_cutoff:.3f}; num of genes={num_of_genes_cutoff}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpx = Biopax(gene_protein, s_omics, project, s_project, root0,\n",
    "             case_list, has_age, has_gender, clone_objects=False,\n",
    "             exp_normalization=exp_normalization, geneset_num=0, \n",
    "             num_min_degs_for_ptw_enr=num_min_degs_for_ptw_enr, \n",
    "             tolerance_pathway_index=tolerance_pathway_index, \n",
    "             s_pathw_enrichm_method = s_pathw_enrichm_method)\n",
    "\n",
    "case = case_list[1]\n",
    "\n",
    "bpx.cfg.set_default_best_lfc_cutoff(normalization, abs_lfc_cutoff=1, fdr_lfc_cutoff=0.05)\n",
    "ret, degs, degs_ensembl, dfdegs = bpx.open_case(case, verbose=False)\n",
    "print(\"\\nEcho Parameters:\")\n",
    "bpx.echo_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble: all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "is_seldata=False\n",
    "\n",
    "with_gender=bpx.has_gender\n",
    "print(f\"with_gender = {with_gender} because has_gender = {bpx.has_gender}\")\n",
    "###################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_seldata, case_list, run_list, chosen_model_list, i_dfp_list, chosen_model_sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiating Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = dic_yml['API_KEY']\n",
    "\n",
    "disease = dic_yml['disease']\n",
    "context_disease = dic_yml['context_disease']\n",
    "n_sentences = dic_yml['n_sentences']\n",
    "chosen_model_sampling = dic_yml['chosen_model_sampling']\n",
    "\n",
    "gem = Gemini(bpx=bpx, is_seldata=is_seldata, disease=disease, context_disease=context_disease, \n",
    "             API_KEY=API_KEY, n_sentences=n_sentences, root0=root0, \n",
    "             chosen_model_list=chosen_model_list, i_dfp_list=i_dfp_list, \n",
    "             chosen_model_sampling=chosen_model_sampling)\n",
    "print(\"\\n\")\n",
    "print(gem.disease, gem.is_seldata, gem.i_dfp_list, gem.chosen_model_list)\n",
    "print(\"Context:\", context_disease)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings: all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gem.set_case(bpx.case, bpx.df_enr, bpx.df_enr0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gem.is_seldata, gem.bpx.case_list, gem.chosen_model_list, gem.i_dfp_list, gem.chosen_model_sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run='run01'\n",
    "case=case_list[0]\n",
    "iq=0\n",
    "i_dfp=0\n",
    "chosen_model=3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose=False\n",
    "df = gem.read_gemini(run=run, case=case, iq=iq, i_dfp=i_dfp, chosen_model=chosen_model, verbose=verbose)\n",
    "print(len(df))\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.curation.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[df.curation=='Yes']), len(df[df.curation!='Yes'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hard reprocucibility (code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ans1, ans2 in [('Yes','Yes'), ('Yes','Possible'), ('Yes','Low evidence'), ('Yes','No'),\n",
    "                   ('No','No'), ('No','Possible'), ('No','Low evidence'), ('No','Yes'),\n",
    "                   ('Yes','xxx'), ('No','xxx'), ('Yes', None), ('No', None), (None, 'Yes'), (None, 'No')]:\n",
    "    print(ans1, ans2, gem.calc_answer_equal(ans1, ans2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run-run reproducibility (RRR) - hard reprodubility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gem.root_gemini_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose=True\n",
    "force=False\n",
    "\n",
    "run1 = run_list[0]\n",
    "run2 = run_list[1]\n",
    "\n",
    "dfall = gem.rrr_concat_2_runs(run1, run2, force=force, verbose=verbose)\n",
    "mu  = dfall.answer_sim.mean()\n",
    "std = dfall.answer_sim.std()\n",
    "\n",
    "dfsim = dfall[dfall.answer_sim >= gem.answer_min_cutoff]\n",
    "nsim = len(dfsim)\n",
    "\n",
    "dfnot = dfall[dfall.answer_sim < gem.answer_min_cutoff]\n",
    "ndiff = len(dfnot)\n",
    "\n",
    "mu, std, nsim, ndiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfall.columns)\n",
    "dfall.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfall = dfall.sort_values(['case', 'iq', 'i_dfp', 'model_name', 'pathway_id'])\n",
    "dfall.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfall.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary_rrr_concat_2_runs\n",
    "\n",
    "text, dfall2, df_case, mu_all, std_all, n, nEq_all, nNot_all = \\\n",
    "gem.calc_run_run_hard_repro(run1, run2, chosen_model_list=chosen_model_list, case_list=case_list, verbose=verbose)\n",
    "\n",
    "## XXXXX inter_model_hard_repro_per_case_%s_between_%s_for_run_%s_%s.tsv\n",
    "print(f\"\\n'{text}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f\"mu {100*mu_all:.1f}% ({std_all:.1f}%), n={n}, nEq_all={nEq_all}, nNot_all={nNot_all}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(dfall2))\n",
    "dfall2.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inter-model reproducibility: IMR - hard reprodubility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose=True\n",
    "force=False\n",
    "\n",
    "# xxxxx\n",
    "\n",
    "one_or_two=1\n",
    "\n",
    "text, df_imr, dfcase_imr, mu_imr, std_imr, n, nsim_imr, nnot_imr = \\\n",
    "gem.calc_inter_model_hard_repro_one_or_two(one_or_two, run1, run2, \n",
    "                                           chosen_model_list=chosen_model_list, case_list=case_list, \n",
    "                                           force=force, verbose=verbose)\n",
    "print(f\"\\n'{text}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imr.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_model_list, mu_imr, std_imr, n, nsim_imr, nnot_imr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcase_imr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hard reproducibility summary for run01 or run02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose=True\n",
    "force=False\n",
    "\n",
    "dfhard = gem.summary_hard_repro(one_or_two=1, run1=run1, run2=run2,\n",
    "                                chosen_model_list=chosen_model_list, case_list=case_list,\n",
    "                                force=force, verbose=verbose)\n",
    "dfhard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfhard = gem.summary_hard_repro(one_or_two=2, run1=run1, run2=run2,\n",
    "                                chosen_model_list=chosen_model_list, case_list=case_list,\n",
    "                                force=force, verbose=verbose)\n",
    "dfhard.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gemini counts\n",
    "  - Count Yes and No per model, run versus iq and i_dfp:\n",
    "    - 2 iq have PubMed inside the search (pubmed=True) and 2 have not\n",
    "    - i_dfp: 0 to 3, 0=enriched, 1=middle, 2=end of the table, and 3=out of enriched table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "force=False\n",
    "verbose=False\n",
    "\n",
    "for run in run_list:\n",
    "    print(\">>>\", run, end=' ')\n",
    "    for chosen_model in chosen_model_list:\n",
    "        print(chosen_model, end='  ')\n",
    "\n",
    "        # old gemini_create_statistical_analysis\n",
    "        dfall = gem.gemini_calc_answers_counts(run=run, case_list=case_list, chosen_model=chosen_model, force=force, verbose=verbose)\n",
    "        print(len(dfall), end=' ')\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose=True\n",
    "\n",
    "run='run01'\n",
    "chosen_model=1\n",
    "\n",
    "# old open_gemini_statistical_analysis\n",
    "dfall = gem.open_gemini_answers_counts(run=run, chosen_model=chosen_model, verbose=verbose)\n",
    "print(len(dfall))\n",
    "\n",
    "dfall.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Soft reproducibility (code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calc dpiv: one run, one model, all cases, all i_dfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose=False\n",
    "force=False\n",
    "\n",
    "for run in run_list:\n",
    "    for chosen_model in chosen_model_list:\n",
    "        print(\">>>\", run, chosen_model)\n",
    "        gem.calc_dfpiv_semantic_consensus_run_per_model(run=run, case_list=case_list,\n",
    "                                                        chosen_model=chosen_model,\n",
    "                                                        force=force, verbose=verbose)\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save yes/no consensus - run, all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose=False\n",
    "force=False\n",
    "\n",
    "for run in run_list:\n",
    "    print(\">>>\", run)\n",
    "    _ = gem.save_gemini_yes_no_run_per_model(run=run, chosen_model_list=chosen_model_list,\n",
    "                                             force=force, verbose=verbose)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open yes-no one model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = True\n",
    "run='run01'\n",
    "consensus='No'\n",
    "consensus='Yes'\n",
    "\n",
    "dfpivc = gem.open_gemini_yes_no_run_per_model(run=run, consensus=consensus, verbose=verbose)\n",
    "print(len(dfpivc))\n",
    "print(dfpivc.columns, '\\n')\n",
    "dfpivc.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfpivc.tail(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Model Consensus Reproducibility (OMCR)\n",
    "  - open_dfpiv_semantic_consensus_run_per_model()\n",
    "  - return: consensus and 4 questins, n_yes, n_no, unanimous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = True\n",
    "run='run01'\n",
    "chosen_model=1\n",
    "\n",
    "dfpiv = gem.open_dfpiv_semantic_consensus_run_per_model(run=run, chosen_model=chosen_model, verbose=verbose)\n",
    "print(len(dfpiv))\n",
    "dfpiv.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfpiv.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfpiv.consensus.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfpiv.run.unique(), dfpiv.case.unique(), dfpiv.i_dfp.unique(), dfpiv.chosen_model.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run-run Consensus Reproducibility (RRCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = True\n",
    "force=False\n",
    "\n",
    "for run in run_list:\n",
    "    print(\">>>\", run)\n",
    "    # calc_gemini_consensus_counts_run_all_models -> \n",
    "    _ = gem.calc_gemini_dfpiva_all_models_one_run(run=run, case_list=case_list, \n",
    "                                                 chosen_model_list=chosen_model_list,\n",
    "                                                 force=force, verbose=verbose)\n",
    "    print(\"\")\n",
    "print(\"\\n------------- end ----------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MMC - multi-model consensus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = True\n",
    "run='run01'\n",
    "\n",
    "# open_gemini_consensus_counts_run_all_models --> open_gemini_dfpiva_all_models_one_run\n",
    "dfpiva = gem.open_gemini_dfpiva_all_models_one_run(run=run, chosen_model_list=chosen_model_list, verbose=verbose)\n",
    "\n",
    "print(len(dfpiva))\n",
    "dfpiva.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfpiva.consensus.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare hard 2 runs (uses dfpiva)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose=False\n",
    "force=False\n",
    "run1='run01'\n",
    "run2='run02'\n",
    "\n",
    "dftot, dfstat = gem.compare_hard_2_runs_total_answers(run1, run2, case_list=case_list, chosen_model_list=chosen_model_list, \n",
    "                                                      pval_cutoff=0.05, force=force, verbose=verbose)\n",
    "dftot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['case', 'run1', 'run2', 'pval_cutoff', 'pval_cutoff_bonf', 's_pvalue', 's_stat', 'stat',\n",
    "       'pvalue', 'dof', 'expected', 'vals1', 'vals2']\n",
    "\n",
    "cols = ['case', 'run1', 'run2', 'pval_cutoff', 'pval_cutoff_bonf', 's_pvalue', 's_stat', 'pvalue', 'dof']\n",
    "dfstat[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfstat.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare soft 2 runs (uses dfpiva)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose=True\n",
    "force=False\n",
    "\n",
    "run='run01'\n",
    "run='run02'\n",
    "\n",
    "dfrep = gem.rrcr_concat_2_runs(run1=run1, run2=run2, chosen_model_list=chosen_model_list, force=force, verbose=verbose)\n",
    "\n",
    "print(len(dfrep))\n",
    "dfrep.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfrep.consensus1.unique(), dfrep.consensus2.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfrep.answer_sim.unique(), dfrep.unanim_equ.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfrep[dfrep.consensus1 == 'Yes'].head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfrep[dfrep.consensus1 == 'Doubt'].head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfg = dfrep.groupby('case').agg({'answer_sim': ['count', 'mean','std'], 'unanim_equ': ['mean','std']}).reset_index()\n",
    "dfg.columns = ['case', 'n', 'repro_mean', 'repro_std', 'unanim_mean','unanim_std']\n",
    "dfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose=True\n",
    "force=False\n",
    "\n",
    "df_stat = gem.rrcr_stats_2_runs(run1, run2, case_list=case_list, chosen_model_list=chosen_model_list, \n",
    "                                force=force, verbose=verbose)\n",
    "\n",
    "\n",
    "cols = ['case', 'mean_repro', 'mean_repro2', 'std_repro', 'mean_unam', 'std_unam', 'n', 'fdr',\n",
    "       'pvalue', 'yes_equal', 'yes_diff', 'no_equal', 'no_diff', 'run1_yes', 'run1_no', 'run2_yes',\n",
    "       'run2_no', 'stat', 'dof', 'expected', 's_stat']\n",
    "\n",
    "cols = ['case', 'mean_repro', 'mean_repro2', 'std_repro', 'mean_unam', 'std_unam', \n",
    "        'n', 'fdr', 'pvalue', \n",
    "        'yes_equal', 'yes_diff', 'no_equal', 'no_diff',\n",
    "        'run1_yes', 'run1_no', 'run2_yes', 'run2_no']\n",
    "\n",
    "df_stat[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_stat.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run-run OMC (one model, one run, consensus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "force=False\n",
    "verbose=False\n",
    "\n",
    "chosen_model=3\n",
    "run='run01'\n",
    "\n",
    "dfrep = gem.calc_soft_one_run_one_model_consensus(run=run, case_list=case_list, chosen_model=chosen_model, \n",
    "\t\t  \t\t\t\t\t \t\t              force=force, verbose=verbose)\n",
    "print(len(dfrep))\n",
    "dfrep.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "force=False\n",
    "verbose=False\n",
    "\n",
    "pd.options.display.float_format = \"{:,.3f}\".format\n",
    "\n",
    "# call many runs, all models, all cases calc_run_model_4DSSQ\n",
    "dfc_stat = gem.calc_soft_consensus_stats_case_i_dfp(run_list=run_list, case_list=case_list,\n",
    "                                                    chosen_model_list=chosen_model_list, i_dfp_list=i_dfp_list,\n",
    "                                                    force=force, verbose=verbose)\n",
    "cols=['run', 'chosen_model', 'model_name', 'case', 'i_dfp', 'mu_consensus_yes',\n",
    "       'std_consensus_yes', 'mu_unanimous', 'std_unanimous', 'n', 'n_yes', 'n_doubt', 'n_no',\n",
    "       'n_unan', 'n_not_unan']\n",
    "cols=['run', 'chosen_model', 'case', 'i_dfp', 'mu_consensus_yes',\n",
    "       'std_consensus_yes', 'mu_unanimous', 'std_unanimous', 'n', 'n_yes', 'n_doubt', 'n_no',\n",
    "       'n_unan', 'n_not_unan']\n",
    "cols2=['run', 'model', 'case', 'i_dfp', 'mu_cons_yes',\n",
    "       'std_cons_yes', 'mu_unan', 'std_unan', 'n', 'n_yes', 'n_doubt', 'n_no',  'n_unan', 'n_not_unan']\n",
    "\n",
    "dfc_stat2 = dfc_stat[cols]\n",
    "dfc_stat2.columns = cols2\n",
    "dfc_stat2.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc_stat.run.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose=True\n",
    "\n",
    "dfrep = gem.open_soft_run_run_one_model_consensus(chosen_model_list=chosen_model_list, verbose=verbose)\n",
    "if dfrep is None or dfrep.empty:\n",
    "    dfrep = pd.DataFrame()\n",
    "\n",
    "print(len(dfrep))\n",
    "\n",
    "case=case_list[0]\n",
    "\n",
    "cols=['run', 'chosen_model', 'case', 'i_dfp', 'mu_consensus_yes',\n",
    "       'std_consensus_yes', 'mu_unanimous', 'std_unanimous', 'n', 'n_yes', 'n_doubt', 'n_no',\n",
    "       'n_unan', 'n_not_unan']\n",
    "cols2=['run', 'model', 'case', 'i_dfp', 'mu_cons_yes',\n",
    "       'std_cons_yes', 'mu_unan', 'std_unan', 'n', 'n_yes', 'n_doubt', 'n_no',  'n_unan', 'n_not_unan']\n",
    "\n",
    "dfrep2 = dfrep[cols]\n",
    "dfrep2.columns = cols2\n",
    "\n",
    "run='run01'\n",
    "case=case_list[0]\n",
    "\n",
    "dfrep2[ (dfrep2.run == run) & (dfrep2.case == case) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analytical case-pathw_group(i_dfp) x Yes, No, Doubt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_dfp_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose=True\n",
    "force=False\n",
    "run='run01'\n",
    "\n",
    "# report_gemini \n",
    "msg, df = gem.calc_analytical_soft_consensus(run=run, case_list=case_list, i_dfp_list=i_dfp_list,  \n",
    "                                             chosen_model_list=chosen_model_list,\n",
    "                                             force=force, verbose=verbose)\n",
    "print(len(df))\n",
    "df.tail(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case = case_list[0]\n",
    "df[df.case == case]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run-run models consensus reproducibility per case i_dfp - list Yes are per Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose=True\n",
    "force=False\n",
    "\n",
    "# calc_soft_run_run_one_model_consensus_repro\n",
    "dfstat = gem.calc_soft_RRCR_stats_per_idfp(run1=run1, run2=run2, chosen_model_list=chosen_model_list, \n",
    "                                           case_list=case_list, i_dfp_list=i_dfp_list,\n",
    "                                           force=force, verbose=verbose)\n",
    "\n",
    "cols=['run1', 'run2', 'case', 'i_dfp', 'n', 'repro_yes_s_stat', 'repro_yes_stat',\n",
    "       'repro_yes_pvalue', 'repro_yes_dof', 'repro_yes_expected', 'unan_s_stat', 'unan_stat',\n",
    "       'unan_pvalue', 'unan_dof', 'unan_expected', 'repro_yes_mu_perc1', 'repro_yes_std_perc1',\n",
    "       'repro_yes_mu_perc2', 'repro_yes_std_perc2', 'unan_mu_perc1', 'unan_std_perc1',\n",
    "       'unan_mu_perc2', 'unan_std_perc2', 'repro_yes_list1', 'repro_yes_list2', 'repro_yes_perc1',\n",
    "       'repro_yes_perc2', 'unan_list1', 'unan_list2', 'unan_perc1', 'unan_perc2']\n",
    "\n",
    "cols=['run1', 'run2', 'case', 'i_dfp', 'n',  'repro_yes_pvalue',  \n",
    "      'repro_yes_mu_perc1', 'repro_yes_std_perc1',\n",
    "      'repro_yes_mu_perc2', 'repro_yes_std_perc2',\n",
    "      'repro_yes_list1', 'repro_yes_list2']\n",
    "\n",
    "dfstat[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=['run1', 'run2', 'case', 'i_dfp', 'n',   'unan_pvalue',\n",
    "      'unan_mu_perc1', 'unan_std_perc1',\n",
    "      'unan_mu_perc2', 'unan_std_perc2',\n",
    "      'unan_list1', 'unan_list2']\n",
    "\n",
    "dfstat[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open dfpiv: one run, one model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case=case_list[0]\n",
    "run='run01'\n",
    "chosen_model1 = 1\n",
    "\n",
    "dfpiv1 = gem.open_dfpiv_gemini_run_case_model(run=run, case=case, chosen_model=chosen_model1, verbose=verbose)\n",
    "print(dfpiv1.columns)\n",
    "print(\"\")\n",
    "print(len(dfpiv1))\n",
    "dfpiv1.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open consensus one model, one run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case=case_list[0]\n",
    "run='run01'\n",
    "chosen_model1 = 1\n",
    "\n",
    "dfpiv1 = gem.open_dfpiv_semantic_consensus_run_per_model(run=run, chosen_model=chosen_model1, verbose=verbose)\n",
    "print(dfpiv1.columns)\n",
    "print(\"\")\n",
    "print(len(dfpiv1))\n",
    "dfpiv1.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open consensus all models, one run (MMC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case=case_list[0]\n",
    "run='run01'\n",
    "chosen_model1 = 1\n",
    "\n",
    "dfpiva = gem.open_gemini_dfpiva_all_models_one_run(run=run, chosen_model_list=chosen_model_list, verbose=verbose)\n",
    "print(dfpiva.columns)\n",
    "print(\"\")\n",
    "print(len(dfpiva))\n",
    "dfpiva.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['case', 'i_dfp', 'pathway_id', 'pathway', \n",
    "        'simple_model_1', 'simple+pubmed_model_1', 'disease_model_1', 'disease+pubmed_model_1', \n",
    "        'simple_model_3', 'simple+pubmed_model_3', 'disease_model_3', 'disease+pubmed_model_3', \n",
    "        'run', 'consensus', 'n_yes', 'n_no', 'unanimous']\n",
    "\n",
    "cols1 = ['case', 'i_dfp', 'pathway_id', 'pathway',\n",
    "         'simp1', 'simpub1', 'dis1', 'dispub1',\n",
    "         'simp3', 'simpub3', 'dis3', 'dispub3', \n",
    "         'run', 'consensus', 'n_yes', 'n_no',\n",
    "       'unanimous']\n",
    "\n",
    "cols2 = ['case', 'i_dfp', 'pathway_id', 'pathway',\n",
    "         'simp1', 'simpub1', 'dis1', 'dispub1',\n",
    "         'simp3', 'simpub3', 'dis3', 'dispub3', \n",
    "         'consensus', 'n_yes', 'n_no',  'unanimous']\n",
    "\n",
    "dfpiva2 = dfpiva.copy()\n",
    "\n",
    "dfpiva2.columns = cols1\n",
    "dfpiva2 = dfpiva2[cols2]\n",
    "print(len(dfpiva2))\n",
    "dfpiva2.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inter-model consensus reproducibility: flexible or not\n",
    "\n",
    "  - method: run_all_inter_model_soft_consensus_repro()\n",
    "    - flexible ~consensus, not flexible ~equal consensus, n_yes, n_no\n",
    "    - for each run, case, i_dfp\n",
    "      - run_inter_model_soft_consensus_repro()\n",
    "        - dfpiv0 = self.open_dfpiv_semantic_consensus_run_per_model(run=run, chosen_model=chosen_model0, verbose=verbose)\n",
    "        - dfpiv1 = self.open_dfpiv_semantic_consensus_run_per_model(run=run, chosen_model=chosen_model1, verbose=verbose)\n",
    "          - filter case and i_dfp\n",
    "          - flexible: equal consensus\n",
    "          - not flexible: equal consensus, n_yes, n_no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "verbose=True\n",
    "force=False\n",
    "\n",
    "chosen_model0=1\n",
    "chosen_model1=3\n",
    "\n",
    "# run_all_comparing_geminis_by_modelcomparing\n",
    "msg, dfc, df_idfp = gem.run_all_inter_model_soft_consensus_repro(chosen_model0=chosen_model0, chosen_model1=chosen_model1,\n",
    "                    \t\t\t\t\t\t\t\t\t\t     run_list=run_list, case_list=case_list,\n",
    "                                                                 force=force, verbose=verbose)\n",
    "\n",
    "# print(msg)\n",
    "cols = ['chosen_model0', 'model_name0', 'chosen_model1', 'model_name1', 'run', 'case', 'i_dfp',\n",
    "        'n', 'mean_consensus', 'std_consensus', 'mean_cons_yes', 'std_cons_yes', 'text']\n",
    "cols = ['run', 'case', 'i_dfp', 'n', 'mean_consensus', 'std_consensus', 'mean_cons_yes', 'std_cons_yes']\n",
    "\n",
    "run='run01'\n",
    "i_dfp=0\n",
    "print(\"Flexible: compare only consensuses\")\n",
    "print(len(df_idfp))\n",
    "df_idfp[(df_idfp.run==run) & (df_idfp.i_dfp==i_dfp) ][cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfc.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['run', 'case', 'chosen_model0', 'model_name0', 'chosen_model1', 'model_name1', 'n',\n",
    "        'n_consensus', 'n_consensus_yes', 'n_unanimous', 'mean_consensus', 'std_consensus',\n",
    "        'mean_cons_yes', 'std_cons_yes', 'mean_unanimous', 'std_unanimous', 'msg']\n",
    "\n",
    "cols = ['case', 'n', 'n_consensus', 'n_consensus_yes', 'n_unanimous',\n",
    "        'mean_consensus', 'std_consensus', 'mean_cons_yes', 'std_cons_yes', 'mean_unanimous', 'std_unanimous', ]\n",
    "\n",
    "run='run01'\n",
    "dfc2 = dfc[(dfc.run==run) ][cols]\n",
    "print(len(dfc2))\n",
    "\n",
    "mu_imcr  = dfc2.mean_consensus.mean()\n",
    "std_imcr = dfc2.mean_consensus.std()\n",
    "\n",
    "print(f\"IMCR is {100*mu_imcr:.1f}% ({100*std_imcr:.1f}%) for {run}\")\n",
    "\n",
    "dfc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run='run02'\n",
    "dfc2 = dfc[(dfc.run==run) ][cols]\n",
    "\n",
    "mu_imcr = dfc2.mean_consensus.mean()\n",
    "std_imcr = dfc2.mean_consensus.std()\n",
    "\n",
    "f\"IMCR is {100*mu_imcr:.1f}% ({100*std_imcr:.1f}%) for {run}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run='run03'\n",
    "dfc2 = dfc[(dfc.run==run) ][cols]\n",
    "\n",
    "mu_imcr = dfc2.mean_consensus.mean()\n",
    "std_imcr = dfc2.mean_consensus.std()\n",
    "\n",
    "f\"IMCR is {100*mu_imcr:.1f}% ({100*std_imcr:.1f}%) for {run}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inter-model consensus venn - detailed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose=False\n",
    "force=False\n",
    "\n",
    "model0=chosen_model_list[0]\n",
    "model1=chosen_model_list[1]\n",
    "\n",
    "only_common_pathways=False\n",
    "\n",
    "for run in run_list:\n",
    "    dfpiv0, model_name0, dfpiv1, model_name1, dff, fname = \\\n",
    "        gem.run_inter_model_soft_consensus_venn(run=run, case_list=case_list, \n",
    "                                                i_dfp_list=i_dfp_list, model0=model0, model1=model1, \n",
    "                                                only_common_pathways=only_common_pathways,\n",
    "                                                force=force, verbose=verbose)\n",
    "\n",
    "    print(run, len(dff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose=True\n",
    "run='run01'\n",
    "\n",
    "dfpiv0, model_name0, dfpiv1, model_name1, dff, fname = \\\n",
    "          gem.run_inter_model_soft_consensus_venn(run=run, case_list=case_list, \n",
    "                                                  i_dfp_list=i_dfp_list, model0=model0, model1=model1, \n",
    "                                                  only_common_pathways=only_common_pathways, verbose=verbose)\n",
    "\n",
    "cols = ['run', 'model0', 'model1', 'case', 'consensus', 'i_dfp', 'n0_pathways', 'n1_pathways',\n",
    "       'n0_consensus', 'n1_consensus', 'n_tot_consensus', 'n_common_consensus',\n",
    "       'n_only0_consensus', 'n_only1_consensus', 'perc0_consensus', 'perc1_consensus',\n",
    "       'perc_commons', 'perc_common_consensus', 'perc_only0_consensus', 'perc_only1_consensus',\n",
    "       'n_pathw_default_tot', 'n_pathw0_new', 'p_hyper0', 'n_pathw1_new', 'p_hyper1',\n",
    "       'n_pathw_defa0_common', 'n_pathw_defa1_common', 'pathw_commons', 'pathw_only0',\n",
    "       'pathw_only1', 'vals0', 'vals1', 'pathw_default_tot', 'pathw_new0', 'pathw_new1',\n",
    "       'pathw_default0', 'pathw_default1']\n",
    "\n",
    "cols = ['run', 'model0', 'model1', 'case', 'consensus', 'i_dfp', 'n0_pathways', 'n1_pathways',\n",
    "       'n0_consensus', 'n1_consensus', 'n_tot_consensus', 'n_common_consensus',\n",
    "       'n_only0_consensus', 'n_only1_consensus', 'perc0_consensus', 'perc1_consensus',\n",
    "       'perc_commons', 'perc_common_consensus', 'perc_only0_consensus', 'perc_only1_consensus']\n",
    "\n",
    "print(\"\")\n",
    "print(len(dff))\n",
    "\n",
    "dff[cols].head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dff.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['run', 'model0', 'model1', 'case', 'consensus', 'i_dfp', 'n0_pathways', 'n1_pathways',\n",
    "       'n0_consensus', 'n1_consensus', 'n_tot_consensus', 'n_common_consensus',\n",
    "       'n_only0_consensus', 'n_only1_consensus', 'perc0_consensus', 'perc1_consensus',\n",
    "       'perc_commons', 'perc_common_consensus', 'perc_only0_consensus', 'perc_only1_consensus',\n",
    "       'vals0', 'vals1', 'pathw_default_tot', 'pathw_new0', 'pathw_new1',\n",
    "       'pathw_default0', 'pathw_default1']\n",
    "\n",
    "\n",
    "i=0\n",
    "case=case_list[i]\n",
    "dff[ (dff.case==case) & (dff.i_dfp.isin([0,3]) ) ][cols].T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New pathways (discover)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "case=case_list[0]\n",
    "\n",
    "df2 = dff[ (dff.case==case) & (dff.i_dfp.isin([0,3]) ) ][cols]\n",
    "\n",
    "mat_new = df2.iloc[0].pathw_new0\n",
    "\n",
    "if isinstance(mat_new, str):\n",
    "    mat_new = eval(mat_new)\n",
    "\n",
    "print(len(mat_new))\n",
    "print(\"\\n\".join(mat_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_new = df2.iloc[0].pathw_new1\n",
    "\n",
    "if isinstance(mat_new, str):\n",
    "    mat_new = eval(mat_new)\n",
    "\n",
    "print(len(mat_new))\n",
    "print(\"\\n\".join(mat_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat0 = df2.iloc[0].vals0\n",
    "\n",
    "if isinstance(mat0, str):\n",
    "    mat0 = eval(mat0)\n",
    "\n",
    "print(len(mat0))\n",
    "print(\"\\n\".join(mat0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat1 = df2.iloc[0].vals1\n",
    "\n",
    "if isinstance(mat1, str):\n",
    "    mat1 = eval(mat1)\n",
    "\n",
    "print(len(mat1))\n",
    "print(\"\\n\".join(mat1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enr_defa = df2.iloc[0].pathw_default_tot\n",
    "\n",
    "if isinstance(enr_defa, str):\n",
    "    enr_defa = eval(enr_defa)\n",
    "\n",
    "print(len(enr_defa))\n",
    "print(\"\\n\".join(enr_defa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(enr_defa), len(mat0), 'not all pathways are Yes for Gemini ->', len(mat_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inter-model statistics Venn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose=False\n",
    "force=False\n",
    "\n",
    "# calc_stat_gemini_compare_2_models\n",
    "df_stat = gem.calc_stat_inter_model_soft_consensus_venn(run_list=run_list, case_list=case_list, \n",
    "                                                         i_dfp_list=i_dfp_list, model0=model0, model1=model1, \n",
    "                                                         only_common_pathways=only_common_pathways, force=force, verbose=verbose)\n",
    "cols = ['run', 'model0', 'model1', 'mean_all', 'std_all', 'mean_enr_yes_no', 'std_enr_yes_no', 'text']\n",
    "cols = ['run', 'model0', 'model1', 'mean_all', 'std_all', 'mean_enr_yes_no', 'std_enr_yes_no']\n",
    "df_stat[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_stat.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inter-models Venn Diagrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose=False\n",
    "\n",
    "run='run01'\n",
    "print_plot=True\n",
    "save=True\n",
    "dpi=300\n",
    "figsize=(12,8)\n",
    "\n",
    "want_run=True\n",
    "%matplotlib inline\n",
    "\n",
    "case_list2 = [case_list[0]]\n",
    "i_dfp_list2 = [0,3]\n",
    "\n",
    "if want_run:\n",
    "    dfpiv0, model_name0, dfpiv1, model_name1, dff, fname = \\\n",
    "           gem.run_inter_model_soft_consensus_venn(run=run, case_list=case_list2, \n",
    "                                              i_dfp_list=i_dfp_list, only_common_pathways=only_common_pathways,\n",
    "                                              model0=model0, model1=model1, \n",
    "                                              force=force, verbose=verbose)\n",
    "\n",
    "    for case in case_list2:\n",
    "        for i_dfp in i_dfp_list2:\n",
    "            for filter in ['Yes', 'No', 'Doubt']:\n",
    "                print(\">>>\", case, filter, len(dfpiv0), len(dfpiv1))\n",
    "                fig, text, perc_commons, commons, n0, n1, only0, only1 = \\\n",
    "                          gem.venn_diagram_between_2models(run=run, filter=filter, case=case, i_dfp=i_dfp,\n",
    "                                                           model_name0=model_name0, df0=dfpiv0,\n",
    "                                                           model_name1=model_name1, df1=dfpiv1,\n",
    "                                                           only_common_pathways=only_common_pathways,\n",
    "                                                           print_plot=print_plot, title_font_size=12,\n",
    "                                                           dpi=dpi, save=save, figsize=figsize, verbose=verbose)\n",
    "        \n",
    "                # print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gem.root_figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consensus count statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose=False\n",
    "force=False\n",
    "\n",
    "for run in run_list:\n",
    "    print(\">>>\", run)\n",
    "    _ = gem.summary_stat_dfpiv_all_models(run=run, case_list=case_list, chosen_model_list=chosen_model_list,\n",
    "    \t\t\t\t\t\t\t\t\t force=force, verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run='run01'\n",
    "verbose=True\n",
    "\n",
    "dfsumm = gem.summary_stat_dfpiv_all_models(run=run, case_list=case_list, chosen_model_list=chosen_model_list, verbose=verbose)\n",
    "print(len(dfsumm))\n",
    "dfsumm.head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### chi2 i_dfp==0 versus all others 3 i_dfps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run='run01'\n",
    "\n",
    "dfstat, dfchi2 = gem.stat_between_dfp_by_run(run=run, case_list=case_list, chosen_model_list=chosen_model_list, verbose=verbose)\n",
    "dfstat.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols=['case', 'question_type', 'i_dfp', 's_stat', 'stat', 'pvalue', 'dof', 'yes_pos_list', 'no_low_list', 'expected', 'df']\n",
    "cols=['case', 'question_type', 'i_dfp', 's_stat', 'pvalue', 'yes_pos_list', 'no_low_list']\n",
    "\n",
    "i=0\n",
    "case = case_list[i]\n",
    "dfchi2[dfchi2.case==case][cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i+=1\n",
    "case = case_list[i]\n",
    "dfchi2[dfchi2.case==case][cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Consensus Yes plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose=True\n",
    "run='run01'\n",
    "\n",
    "dfsumm = gem.open_summary_stat_dfpiv_all_models(run=run, case_list=case_list, chosen_model_list=chosen_model_list, verbose=verbose)\n",
    "print(len(dfsumm))\n",
    "dfsumm.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose=True\n",
    "run='run01'\n",
    "savePlot=True\n",
    "normalized=False\n",
    "\n",
    "dic = gem.barplot_yes_no_idfp_models(run=run, case_list=case_list, chosen_model_list=chosen_model_list,\n",
    "                                     i_dfp_list=i_dfp_list, split=1, normalized=normalized,\n",
    "                                     width=1100, height=600, fontsize=14, fontcolor='black',\n",
    "                                     margin=dict( l=20, r=20, b=100, t=160, pad=4), plot_bgcolor=\"whitesmoke\",\n",
    "                                     xaxis_title=\"cases\", yaxis_title='n Yes',\n",
    "                                     minus_y_idfp=-1.5, minus_y_case=-5, \n",
    "                                     line_width=2, title_font_color='navy', title_font_size=16,\n",
    "                                     annot_fontfamily=\"Arial, monospace\", annot_fontsize=12, \n",
    "                                     annot_fontcolor='black', savePlot=savePlot, verbose=verbose)\n",
    "for key, fig in dic.items():\n",
    "    if fig: fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized=True\n",
    "\n",
    "dic = gem.barplot_yes_no_idfp_models(run=run, case_list=case_list, chosen_model_list=chosen_model_list,\n",
    "                                     i_dfp_list=i_dfp_list, split=1, normalized=True,\n",
    "                                     width=1100, height=600, fontsize=14, fontcolor='black',\n",
    "                                     margin=dict( l=20, r=20, b=100, t=160, pad=4), plot_bgcolor=\"whitesmoke\",\n",
    "                                     xaxis_title=\"cases\", yaxis_title='n Yes',\n",
    "                                     minus_y_idfp=-1.5, minus_y_case=-5, \n",
    "                                     line_width=2, title_font_color='navy', title_font_size=16,\n",
    "                                     annot_fontfamily=\"Arial, monospace\", annot_fontsize=12, \n",
    "                                     annot_fontcolor='black', savePlot=savePlot, verbose=verbose)\n",
    "for key, fig in dic.items():\n",
    "    if fig: fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run='run01'\n",
    "\n",
    "fig = gem.barplot_yes_no_per_case_run(run=run, case_list=case_list, \n",
    "                                      chosen_model_list=chosen_model_list, i_dfp_list=i_dfp_list,\n",
    "                                      width=1900, height=600, fontsize=12, fontcolor='black',\n",
    "                                      xaxis_title=\"cases-idfp-models\", yaxis_title='n answers',\n",
    "                                      minus_y_yes_no=-3, minus_y_i_dfp=-6, minus_y_case=-9,\n",
    "                                      annot_fontfamily=\"Arial, monospace\", annot_fontsize=12, \n",
    "                                      annot_fontcolor='black', savePlot=True, verbose=False)\n",
    "\n",
    "if fig: fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run='run02'\n",
    "\n",
    "fig = gem.barplot_yes_no_per_case_run(run=run, case_list=case_list, \n",
    "                                      chosen_model_list=chosen_model_list, i_dfp_list=i_dfp_list,\n",
    "                                      width=1900, height=600, fontsize=12, fontcolor='black',\n",
    "                                      xaxis_title=\"cases-idfp-models\", yaxis_title='n answers',\n",
    "                                      minus_y_yes_no=-3, minus_y_i_dfp=-6, minus_y_case=-9,\n",
    "                                      annot_fontfamily=\"Arial, monospace\", annot_fontsize=12, \n",
    "                                      annot_fontcolor='black', savePlot=True, verbose=False)\n",
    "\n",
    "if fig: fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing runs - summary gemini consensus - all models\n",
    "  - for each run\n",
    "  - for all models and i_dfp (0..3)\n",
    "  - summarise total Yes, No, Doubts, unamimous, not_unanimous\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "verbose=False\n",
    "force=False\n",
    "save_files=force\n",
    "\n",
    "text, dfcons = gem.calc_gemini_summary_consensus_statitics_idfp(run_list=run_list, chosen_model_list=chosen_model_list, \n",
    "                                                                case_list=case_list, save_files=save_files,\n",
    "                                                                force=force, verbose=verbose)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text, dfcons = gem.open_gemini_summary_consensus_statitics_idfp(chosen_model_list=chosen_model_list, verbose=True)\n",
    "print(len(dfcons))\n",
    "\n",
    "run='run01'\n",
    "i=0\n",
    "case=case_list[i]\n",
    "\n",
    "print(\">>>\", case, '\\n')\n",
    "dfcons[ (dfcons.run==run) & (dfcons.case==case)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i+=1\n",
    "case=case_list[i]\n",
    "\n",
    "print(\">>>\", case, '\\n')\n",
    "dfcons[ (dfcons.run==run) & (dfcons.case==case)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose=True\n",
    "run='run01'\n",
    "i_dfp=0\n",
    "\n",
    "dfa = gem.get_gemini_summary_consensus_statitics_idfp(run=run, i_dfp=i_dfp, chosen_model_list=chosen_model_list, verbose=verbose)\n",
    "dfa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unanimous Reproduciblity - UR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['run', 'case', 'i_dfp', 'consensus', 'n', 'unanimous', 'not_unanimous']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "verbose=False\n",
    "force=False\n",
    "save_files=force\n",
    "\n",
    "text, dfconsa = gem.calc_gemini_summary_consensus_statitics(run_list=run_list, chosen_model_list=chosen_model_list, \n",
    "                                                           case_list=case_list, force=force, verbose=verbose)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run='run01'\n",
    "dfconsa[(dfconsa.run == run) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run='run02'\n",
    "dfconsa[dfconsa.run == run]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
