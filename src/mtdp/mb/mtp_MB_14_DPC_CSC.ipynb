{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from platform import python_version\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crowdsource consensus (CSC)\n",
    "  - The CSC is the consensus of Gemini MMC, PubMed answers, and Human consensus.\n",
    "  - Each of these three sources holds equal weight in this composite measure.\n",
    "  - Crowdsource consensus can be described as the consensus of the consensuses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 Sources ~ 2CRSP\n",
    "  - Gemini MMC\n",
    "  - PubMed answers\n",
    "  - Human consensus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.width', 100)\n",
    "pd.set_option('max_colwidth', 80)\n",
    "pd.set_option(\"display.precision\", 3)\n",
    "\n",
    "import yaml\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_context(\"notebook\", font_scale=1.4)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "%matplotlib inline\n",
    "\n",
    "sys.path.insert(1, '../src/')\n",
    "\n",
    "from Basic import *\n",
    "from biopax_lib import *\n",
    "from gemini_lib import *\n",
    "from pubmed_lib import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>:root { --jp-notebook-max-width: 100% !important; }</style>\"))\n",
    "\n",
    "with open('params.yml', 'r') as file:\n",
    "    dic_yml=yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root0=dic_yml['root0']\n",
    "root_data_aux=dic_yml['root_data_aux']\n",
    "email=dic_yml['email']\n",
    "\n",
    "project=dic_yml['project']\n",
    "s_project=dic_yml['s_project']\n",
    "\n",
    "gene_protein=dic_yml['gene_protein']\n",
    "s_omics=dic_yml['s_omics']\n",
    "\n",
    "has_age=dic_yml['has_age']\n",
    "has_gender=dic_yml['has_gender']\n",
    "\n",
    "want_normalized=dic_yml['want_normalized']\n",
    "\n",
    "abs_lfc_cutoff_inf=dic_yml['abs_lfc_cutoff_inf']\n",
    "s_pathw_enrichm_method=dic_yml['s_pathw_enrichm_method']\n",
    "num_min_degs_for_ptw_enr=dic_yml['num_min_degs_for_ptw_enr']\n",
    "\n",
    "tolerance_pathway_index=dic_yml['tolerance_pathway_index']\n",
    "type_sat_ptw_index=dic_yml['type_sat_ptw_index']\n",
    "saturation_lfc_index=dic_yml['saturation_lfc_index']\n",
    "chosen_model_sampling=dic_yml['chosen_model_sampling']\n",
    "\n",
    "case_list=dic_yml['case_list']\n",
    "case_sel_list=dic_yml['case_sel_list']\n",
    "\n",
    "pval_pathway_cutoff=dic_yml['pval_pathway_cutoff']\n",
    "fdr_pathway_cutoff=dic_yml['fdr_pathway_cutoff']\n",
    "num_of_genes_cutoff=dic_yml['num_of_genes_cutoff']\n",
    "\n",
    "run_list=dic_yml['run_list']\n",
    "chosen_model_list=dic_yml['chosen_model_list']\n",
    "i_dfp_list=dic_yml['i_dfp_list']\n",
    "\n",
    "exp_normalization='quantile_norm' if want_normalized else None\n",
    "normalization='not_normalized' if exp_normalization is None else exp_normalization\n",
    "\n",
    "cfg=Config(project, s_project, case_list, root0)\n",
    "\n",
    "case=case_list[0]\n",
    "\n",
    "n_genes_annot_ptw, n_degs, n_degs_in_ptw, n_degs_not_in_ptw, degs_in_all_ratio=-1,-1,-1,-1,-1\n",
    "abs_lfc_cutoff, fdr_lfc_cutoff, n_degs, n_degs_up, n_degs_dw=cfg.get_best_lfc_cutoff(case, 'not_normalized')\n",
    "\n",
    "print(f\"G/P LFC cutoffs: lfc={abs_lfc_cutoff:.3f}; fdr={fdr_lfc_cutoff:.3f}\")\n",
    "print(f\"Pathway cutoffs: pval={pval_pathway_cutoff:.3f}; fdr={fdr_pathway_cutoff:.3f}; num of genes={num_of_genes_cutoff}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpx=Biopax(gene_protein, s_omics, project, s_project, root0,\n",
    "           case_list, has_age, has_gender, clone_objects=False,\n",
    "           exp_normalization=exp_normalization, geneset_num=0, \n",
    "           num_min_degs_for_ptw_enr=num_min_degs_for_ptw_enr, \n",
    "           tolerance_pathway_index=tolerance_pathway_index, \n",
    "           s_pathw_enrichm_method=s_pathw_enrichm_method,\n",
    "           abs_lfc_cutoff_inf=abs_lfc_cutoff_inf, \n",
    "           type_sat_ptw_index=type_sat_ptw_index, saturation_lfc_index=saturation_lfc_index)\n",
    "\n",
    "case=case_list[0]\n",
    "\n",
    "bpx.cfg.set_default_best_lfc_cutoff(normalization, abs_lfc_cutoff=1, fdr_lfc_cutoff=0.05)\n",
    "ret, degs, degs_ensembl, dfdegs=bpx.open_case(case, verbose=False)\n",
    "print(\"\\nEcho Parameters:\")\n",
    "bpx.echo_parameters()\n",
    "\n",
    "geneset_num=bpx.geneset_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSD (multiple sources dataset): is_seldata=True - 2 cases randomly selected pathways (2CRSP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "is_seldata=True\n",
    "if is_seldata==True: i_dfp_list = [0]\n",
    "i_dfp=0\n",
    "\n",
    "case_list = case_sel_list\n",
    "case_sel0 = case_sel_list[0]\n",
    "case_sel1 = case_sel_list[1]\n",
    "\n",
    "with_gender=bpx.has_gender\n",
    "with_gender_list = [False, True] if with_gender else [False]\n",
    "\n",
    "print(f\"with_gender = {with_gender} because has_gender = {bpx.has_gender}\")\n",
    "##########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_seldata, case_list, run_list, chosen_model_list, i_dfp_list, chosen_model_sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiating Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY=dic_yml['API_KEY']\n",
    "\n",
    "disease=dic_yml['disease']\n",
    "context_disease=dic_yml['context_disease']\n",
    "n_sentences=dic_yml['n_sentences']\n",
    "chosen_model_sampling=dic_yml['chosen_model_sampling']\n",
    "\n",
    "gem=Gemini(bpx=bpx, is_seldata=is_seldata, disease=disease, context_disease=context_disease, \n",
    "           API_KEY=API_KEY, n_sentences=n_sentences, root0=root0, \n",
    "           chosen_model_list=chosen_model_list, i_dfp_list=i_dfp_list, chosen_model_sampling=chosen_model_sampling)\n",
    "print(\"\\n\")\n",
    "print(gem.disease, gem.is_seldata, gem.i_dfp_list, gem.chosen_model_list)\n",
    "print(\"Context:\", context_disease)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gem.set_case(bpx.case, bpx.df_enr, bpx.df_enr0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gem.is_seldata, gem.bpx.case_list, gem.chosen_model_list, gem.i_dfp_list, gem.chosen_model_sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = s_project\n",
    "\n",
    "terms1_param=dic_yml['terms1_param']\n",
    "terms2_param=dic_yml['terms2_param']\n",
    "terms_not_param=dic_yml['terms_not_param']\n",
    "connective_param=dic_yml['connective_param']\n",
    "\n",
    "remove_synonym_list=dic_yml['remove_synonym_list']\n",
    "inidate=dic_yml['inidate']\n",
    "enddate=dic_yml['enddate']\n",
    "\n",
    "verbose_query=dic_yml['verbose_query']\n",
    "force_query=dic_yml['force_query']\n",
    "\n",
    "sleep_entrez=dic_yml['sleep_entrez']\n",
    "retmax=dic_yml['retmax']\n",
    "\n",
    "try_all_text=dic_yml['try_all_text']\n",
    "text_quote=dic_yml['text_quote']\n",
    "dec_ncpus=dic_yml['dec_ncpus']\n",
    "\n",
    "sleep_TIKA=dic_yml['sleep_TIKA']\n",
    "min_words_text=dic_yml['min_words_text']\n",
    "\n",
    "print(f\"prefix={prefix}, dates: {inidate} to {enddate}\")\n",
    "print(f\"terms1: {terms1_param}\")\n",
    "print(f\"terms_not: {terms_not_param}\\n\")\n",
    "\n",
    "pub = Pubmed(bpx, gem, email, prefix, root0, \n",
    "             inidate=inidate, enddate=enddate, \n",
    "\t\t\t terms1_param=terms1_param, terms2_param=terms2_param, \n",
    "\t\t\t terms_not_param=terms_not_param, connective_param=connective_param,\n",
    "             remove_synonym_list=remove_synonym_list, sleep_entrez=sleep_entrez, \n",
    "             retmax=retmax, try_all_text=True, text_quote='',\n",
    "             root_data_aux=root_data_aux, dec_ncpus=dec_ncpus,\n",
    "             sleep_TIKA=sleep_TIKA, min_words_text=min_words_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=False\n",
    "force=False\n",
    "verbose=False\n",
    "\n",
    "chosen_model=3\n",
    "gemini_model=gem.gemini_models[chosen_model]\n",
    "pub.gem.set_gemini_num_model(chosen_model, verbose=verbose)\n",
    "\n",
    "# for selected data\n",
    "query_type='strong'\n",
    "N=30\n",
    "\n",
    "case=case_sel0\n",
    "print(\"\")\n",
    "dfsel = gem.open_yes_no_sampling(case=case, N=N, query_type=query_type, verbose=True)\n",
    "print(\"\")\n",
    "dfsel.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pub.gem.is_seldata, pub.gem.i_dfp_list, pub.gem.root_gemini0, case_list, with_gender_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calc Gemini consensus counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pub.gem.chosen_model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose=True\n",
    "force=False\n",
    "\n",
    "for run in run_list:\n",
    "    print(\">>>\", run, end=' ')\n",
    "    dfpiva = pub.gem.calc_gemini_dfpiva_all_models_one_run(run=run, case_list=case_list, \n",
    "                                                      chosen_model_list=chosen_model_list, \n",
    "                                                      force=force, verbose=verbose)\n",
    "    if dfpiva is None:\n",
    "        print(\"None\")\n",
    "    else:\n",
    "        print(len(dfpiva))\n",
    "\n",
    "print(\"---------------- end -----------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose=True\n",
    "run='run01'\n",
    "\n",
    "dfpiva = gem.open_gemini_dfpiva_all_models_one_run(run=run,  chosen_model_list=chosen_model_list, verbose=verbose)\n",
    "# print(dfpiva.columns)\n",
    "\n",
    "print(len(dfpiva))\n",
    "case = case_list[0]\n",
    "df2 = dfpiva[dfpiva.case==case]\n",
    "print(len(df2))\n",
    "df2.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case = case_list[1]\n",
    "df2 = dfpiva[dfpiva.case==case]\n",
    "print(len(df2))\n",
    "df2.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfpiva.case.unique(), dfpiva.i_dfp.unique(), dfpiva.run.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose=False\n",
    "\n",
    "run='run01'\n",
    "case=case_list[0]\n",
    "consensus='Yes'\n",
    "\n",
    "dfpiv2 = pub.gem.open_gemini_consensus_counts_run_filter_idfp_consensus_run_all_models(run=run, i_dfp=i_dfp,\n",
    "                                                                        chosen_model_list=chosen_model_list,\n",
    "                                                                        consensus=consensus, verbose=verbose)\n",
    "if dfpiv2 is None:\n",
    "    dfpiv2 = pd.DataFrame()\n",
    "\n",
    "print(\">>>\", run, i_dfp, case, \"\\n\\n\")\n",
    "\n",
    "dfpiv3 = dfpiv2[dfpiv2.case == case]\n",
    "\n",
    "print(len(dfpiv3))\n",
    "dfpiv3.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\".join(dfpiv3.pathway))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=1\n",
    "case=case_list[i]\n",
    "print(\">>>\", case, \"\\n\\n\")\n",
    "\n",
    "dfpiv3 = dfpiv2[dfpiv2.case == case]\n",
    "\n",
    "print(len(dfpiv3))\n",
    "dfpiv3.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reviewers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lib for Excel\n",
    "# !pip3 install openpyxl --force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pro = ['aparecida', 'fabio',  'kadu']\n",
    "stu = ['vinicius', 'juliana', 'victor', 'gabriela', 'guilherme']\n",
    "\n",
    "pub.set_researchers_students(pro=pro, stu=stu)\n",
    "\n",
    "print(\">>>\", pub.reviewers, \"\\n\\n\")\n",
    "\n",
    "group_names = [pro, stu]\n",
    "group_list=['pro', 'stu']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging reviewers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose=True\n",
    "force=False\n",
    "\n",
    "dic = pub.merge_reviewers_answers(case_list=case_sel_list, \n",
    "                                  s_start='sampling_case_', query_type='query_type_strong_', force=force, verbose=verbose)\n",
    "print(len(dic))\n",
    "cases = list(dic.keys())\n",
    "\";\".join(cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic[case_sel0].head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic[case_sel1].head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case0 = case_sel0\n",
    "dff1 = pub.open_reviewers_answers(case0, verbose=True)\n",
    "print(len(dff1))\n",
    "dff1.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case0 = case_sel1\n",
    "dff2 = pub.open_reviewers_answers(case0, verbose=True)\n",
    "print(len(dff2))\n",
    "dff2.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reviewers per group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose=False\n",
    "force=False\n",
    "\n",
    "dfsf = pub.compare_2_reviewer_groups(group_names=group_names, group_list=group_list, case_list=case_sel_list,\n",
    "                                     force=force, verbose=verbose)\n",
    "\n",
    "pd.options.display.float_format = '{:,.3f}'.format\n",
    "\n",
    "cols = ['group', 'case', 'n', 'perc_consensus_yes', 'perc_consensus_no', 'perc_consensus_doubt',\n",
    "        'n_consensus_yes', 'n_consensus_no', 'n_consensus_doubt', 'pathways_yes', 'pathways_no',\n",
    "        'pathways_doubt', 'researchers']\n",
    "cols = ['group', 'case', 'n', 'perc_consensus_yes', 'perc_consensus_no', 'perc_consensus_doubt',\n",
    "        'n_consensus_yes', 'n_consensus_no', 'n_consensus_doubt']\n",
    "\n",
    "dfsf[cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reviewers consensus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose=False\n",
    "df1 = pub.open_reviewers_answers_group_case(group='pro', case=case_sel0, verbose=True)\n",
    "df1.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pub.open_reviewers_answers_group_case(group='pro', case=case_sel1, verbose=verbose)\n",
    "df2.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pub.open_reviewers_answers_group_case(group='stu', case=case_sel0, verbose=verbose)\n",
    "df3.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = pub.open_reviewers_answers_group_case(group='stu', case=case_sel1, verbose=verbose)\n",
    "df4.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run with_gender False - Medulloblastoma\n",
    "#### calc_all_gemini_x_reviewers_agreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose=True\n",
    "force=False\n",
    "\n",
    "dic_gem = pub.calc_all_gemini_x_reviewers_agreement(run_list=run_list, case_list=case_list,  \n",
    "                                                    chosen_model_list=chosen_model_list, \n",
    "                                                    force=force, verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_gem.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = list(dic_gem.keys())\n",
    "\n",
    "key = keys[0]\n",
    "print(\"Agreement with Gemini (consensus)\", key)\n",
    "\n",
    "dfa = dic_gem[key]\n",
    "\n",
    "cols1 = ['run', 'case', 'person', 'n_total', 'n_yes_gemini_cons', 'n_no_gemini_cons', 'n_agree',\n",
    "         'n_agree_yes', 'n_agree_no', 'agree', 'agree_std', 'agree_yes', 'agree_std_yes', 'agree_no',\n",
    "         'agree_std_no', 'perc_agree', 'perc_agree_yes', 'perc_agree_no', 'rank']\n",
    "\n",
    "cols1 = ['person', 'case', 'n_total', 'n_yes_gemini_cons', 'n_no_gemini_cons', 'n_agree',\n",
    "         'n_agree_yes', 'n_agree_no', 'agree', 'agree_std', 'agree_yes', 'agree_no', 'rank']\n",
    "dfa = dfa[cols1]\n",
    "\n",
    "cols2 = ['person', 'case', 'n_total', 'n_yes', 'n_no', 'n_agree', 'n_agree_yes', 'n_agree_no',\n",
    "         'agree', 'agree_std', 'agree_yes', 'agree_no', 'rank']\n",
    "dfa.columns = cols2\n",
    "\n",
    "def style_060(v, props=''):\n",
    "    if isinstance(v, float):\n",
    "        return props if v >= 0.6 else None\n",
    "    return None\n",
    "\n",
    "def style_030(v, props=''):\n",
    "    if isinstance(v, float):\n",
    "        return props if v < 0.3 else None\n",
    "    return None\n",
    "\n",
    "s2 = dfa.style.map(style_060, props='color:cyan;').\\\n",
    "               map(style_030, props='color:tomato;').\\\n",
    "               map(lambda v: None if not isinstance(v, float) else ('opacity: 70%;' if (v < 0.2) and (v > -0.2) else None))\n",
    "s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = keys[1]\n",
    "print(\"Agreement with Gemini (consensus)\", key)\n",
    "dfa = dic_gem[key]\n",
    "\n",
    "dfa = dic_gem[key]\n",
    "dfa = dfa[cols1]\n",
    "dfa.columns = cols2\n",
    "\n",
    "s2 = dfa.style.map(style_060, props='color:cyan;').\\\n",
    "               map(style_030, props='color:tomato;').\\\n",
    "               map(lambda v: None if not isinstance(v, float) else ('opacity: 70%;' if (v < 0.2) and (v > -0.2) else None))\n",
    "s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PubMed agreements\n",
    "  - rank: classification\n",
    "  - n_total: number of pathways\n",
    "  - n_agree: number of pathways that the reviewer agree with PubMed (Yes x Yes, No x No)\n",
    "    - n_agree_yes: number of pathways that the reviewer agree with PubMed Yes x Yes\n",
    "    - n_agree_no: number of pathways that the reviewer agree with PubMed No x No"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose=False\n",
    "force=False\n",
    "\n",
    "dic_pub = pub.calc_all_pubmed_x_reviewers_agreement(case_list=case_list, i_dfp_list=i_dfp_list, \n",
    "                                                    with_gender_list=with_gender_list, force=force, verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_pub.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = list(dic_pub.keys())\n",
    "\n",
    "key = keys[0]\n",
    "print(\"Agreement with PubMed\", key)\n",
    "df_wnt = dic_pub[key]\n",
    "\n",
    "cols1 = ['person', 'case', 'n_total', 'n_yes_pub_has_pmid', 'n_no_pub_has_pmid', 'n_agree',\n",
    "         'n_agree_yes', 'n_agree_no', 'agree', 'agree_std', 'agree_yes', 'agree_std_yes', 'agree_no',\n",
    "         'agree_std_no', 'perc_agree', 'perc_agree_yes', 'perc_agree_no', 'rank']\n",
    "\n",
    "cols1 = ['person', 'case', 'n_total', 'n_yes_pub_has_pmid', 'n_no_pub_has_pmid', 'n_agree',\n",
    "         'n_agree_yes', 'n_agree_no', 'agree', 'agree_std', 'agree_yes', 'agree_no', 'rank']\n",
    "df_wnt = df_wnt[cols1]\n",
    "\n",
    "cols2 = ['person', 'case', 'n_total', 'n_yes', 'n_no', 'n_agree', 'n_agree_yes', 'n_agree_no',\n",
    "         'agree', 'agree_std', 'agree_yes', 'agree_no', 'rank']\n",
    "df_wnt.columns = cols2\n",
    "\n",
    "\n",
    "dfsty = df_wnt.style.map(style_060, props='color:cyan;').\\\n",
    "                     map(style_030, props='color:tomato;').\\\n",
    "                     map(lambda v: None if not isinstance(v, float) else ('opacity: 70%;' if (v < 0.2) and (v > -0.2) else None))\n",
    "dfsty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = keys[1]\n",
    "print(\"Agreement with PubMed\", key)\n",
    "df_g4 = dic_pub[key]\n",
    "\n",
    "df_g4 = df_g4[cols1]\n",
    "df_g4.columns = cols2\n",
    "\n",
    "dfsty = df_g4.style.map(style_060, props='color:cyan;').\\\n",
    "                    map(style_030, props='color:tomato;').\\\n",
    "                    map(lambda v: None if not isinstance(v, float) else ('opacity: 70%;' if (v < 0.2) and (v > -0.2) else None))\n",
    "dfsty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics PubMed WNT x G4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_stat, stat, pvalue, dof, expected = pub.calc_similarity_false_true(df_wnt, df_g4)\n",
    "s_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge all 3 sources and calc crowdsource: without gender is MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose=False\n",
    "force=False\n",
    "person_list = pub.pro + pub.stu\n",
    "\n",
    "pub.merge_all_3sources_calc_crowd(person_list=person_list, run_list=run_list, case_list=case_list, \n",
    "                                  with_gender_list=with_gender_list, force=force, verbose=verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### open_gemini_agreement_person()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose=True\n",
    "\n",
    "run='run01'\n",
    "case = case_list[0]\n",
    "\n",
    "person = person_list[4]\n",
    "print(\">>>\", person)\n",
    "\n",
    "dfrev_gem = pub.open_gemini_agreement_person(run=run, case=case, person=person, verbose=verbose)\n",
    "print(len(dfrev_gem))\n",
    "dfrev_gem.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case = case_list[1]\n",
    "\n",
    "dfrev_gem = pub.open_gemini_agreement_person(run=run, case=case, person=person, verbose=verbose)\n",
    "print(len(dfrev_gem))\n",
    "dfrev_gem.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### open_pubmed_agreement()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case = case_list[0]\n",
    "\n",
    "dfrev_pub = pub.open_pubmed_agreement(with_gender=with_gender, case=case, person=person, verbose=verbose)\n",
    "print(len(dfrev_pub))\n",
    "dfrev_pub.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case = case_list[1]\n",
    "\n",
    "dfrev_pub = pub.open_pubmed_agreement(with_gender=with_gender, case=case, person=person, verbose=verbose)\n",
    "print(len(dfrev_pub))\n",
    "dfrev_pub.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crowdsource merge 3 sources: return dfcrowd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose=True\n",
    "force=False\n",
    "run='run01'\n",
    "case=case_list[0]\n",
    "\n",
    "dfcrowd = pub.merge_3sources_calc_crowd(with_gender=with_gender, person_list=person_list, run=run, \n",
    "                                        case=case, force=force, verbose=verbose)\n",
    "dfcrowd.head(3).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case=case_list[1]\n",
    "\n",
    "cols = ['case', 'run', 'with_gender', 'pathway_id', 'pathway', 'i_dfp', 'n_pmid', 'pub_has_pmid',  'gem_consensus',\n",
    "       'n_yes_gem', 'agree_pubgem', 'rev_consensus', 'rev_consensus_n_yes',\n",
    "       'rev_consensus_n_no', 'unanimous_reviewers']\n",
    "\n",
    "dfcrowd = pub.merge_3sources_calc_crowd(with_gender=with_gender, person_list=person_list, run=run, \n",
    "                                        case=case, force=False, verbose=verbose)\n",
    "print(len(dfcrowd))\n",
    "dfcrowd[cols].head(3).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crowd and 3Sources Agreements\n",
    "\n",
    "  - count_all_crowd_agreements()\n",
    "    - count_crowd_agreements()\n",
    "      - return dfcrowd\n",
    "      - get all agrees and transform in accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose=False\n",
    "force=False\n",
    "\n",
    "pub.count_all_crowd_agreements(with_gender_list=with_gender_list, person_list=person_list,\n",
    "                               run_list=run_list, case_list=case_list, force=force, verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose=False\n",
    "\n",
    "for run in run_list:\n",
    "    print(\">>>\", run)\n",
    "    for case in case_list:\n",
    "        df_count = pub.count_crowd_agreements(with_gender=with_gender, person_list=person_list, run=run, case=case, verbose=verbose)\n",
    "        txt = f\"\\tcase {case:15} <crowd> {100*df_count.crowd_yes.mean():.1f}% <pubmed> {100*df_count.pubmed_has.mean():.1f}%, \" + \\\n",
    "              f\"<gemini> {100*df_count.gemini_yes.mean():.1f}%, and <reviewers> {100*df_count.review_yes.mean():.1f}%\"\n",
    "        print(txt)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_count.head(3).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracies\n",
    "  - calc_all_crowd_accuracies()\n",
    "    - loop run, case, with_gender\n",
    "      - dic2_calc_crowd_accuracies(receive dic2)\n",
    "    - calc: df_accu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose=False\n",
    "force=False\n",
    "\n",
    "print(\">>> person_list:\", person_list, '\\n')\n",
    "\n",
    "all_text, dfall_crowd, df_accu = pub.calc_all_crowd_accuracies(person_list=person_list, run_list=run_list,\n",
    "                                                               case_list=case_list, with_gender_list=with_gender_list, \n",
    "                                                               force=force, verbose=verbose)\n",
    "\n",
    "len(dfall_crowd), dfall_crowd.run.unique(), dfall_crowd.case.unique(), dfall_crowd.with_gender.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfall_crowd.groupby(['run', 'case', 'with_gender']).count().reset_index().iloc[:,:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Crowdsource summary text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(all_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 sources accuracy\n",
    "  - Pathways_crowd: how many pathways have Yes as responses\n",
    "  - 50% of the pathways of the 2CRSP were Yes and 50% No\n",
    "    - perc_pathws_crowd ~ 53%\n",
    "    - perc_pathws_pubmed ~ 40%\n",
    "    - perc_pathws_gemini ~ 66.7%\n",
    "    - perc_pathws_reviewers ~ 53.3%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_accu.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run='run01'\n",
    "\n",
    "for case in case_list:\n",
    "    row = df_accu[ (df_accu.run == run) & (df_accu.case == case)].iloc[0]\n",
    "    accu_gemini     = row.accu_gemini\n",
    "    std_accu_gemini = row.std_accu_gemini\n",
    "    accu_pubmed     = row.accu_pubmed\n",
    "    std_accu_pubmed = row.std_accu_pubmed\n",
    "    accu_review     = row.accu_review\n",
    "    std_accu_review = row.std_accu_review\n",
    "\n",
    "    msg  = f\"for {run} case {case} the accuracies are:\\n\"\n",
    "    msg += f\"\\tGemini    {100*accu_gemini:.1f}% ({100*std_accu_gemini:.1f}%)\\n\"\n",
    "    msg += f\"\\tPubMed    {100*accu_pubmed:.1f}% ({100*std_accu_pubmed:.1f}%)\\n\"\n",
    "    msg += f\"\\tReviewers {100*accu_review:.1f}% ({100*std_accu_review:.1f}%)\\n\\n\"\n",
    "    print(msg)\n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count = pub.count_crowd_agreements(with_gender=with_gender, person_list=person_list, run=run, case=case, verbose=verbose)\n",
    "print(len(df_count))\n",
    "df_count.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_accu.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text, dfall_crowd, df_accu = pub.calc_all_crowd_accuracies(person_list=person_list, run_list=run_list,\n",
    "                                                               case_list=case_list, with_gender_list=with_gender_list, \n",
    "                                                               force=False, verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x for x in dfall_crowd.columns if 'agree' in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_accu.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x for x in df_accu.columns if 'perc' in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing 3Sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose=True\n",
    "force=False\n",
    "\n",
    "dfbinv = pub.stat_3sources_binary_vars(run_list=run_list, case_list=case_list,\n",
    "                                       with_gender_list=with_gender_list, person_list=person_list,\n",
    "                                       force=force, verbose=verbose)\n",
    "\n",
    "run='run01'\n",
    "df2 = dfbinv[(dfbinv.run==run) & (dfbinv.with_gender==with_gender)]\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Significative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[df2.fdr < 0.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CSC is only one: by gender False for MB\n",
    "  - therefore, gemini accuracy is only one\n",
    "  - PubMed accuracy is only one for MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run='run01'\n",
    "dfbinv = pub.dfbinv\n",
    "case=case_list[1]\n",
    "\n",
    "df2 = dfbinv[(dfbinv.run==run) & (dfbinv.case==case) & (dfbinv.with_gender==with_gender)]\n",
    "print(len(df2))\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pub.dfbinv['compare'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run='run01'\n",
    "\n",
    "case = case_list[0]\n",
    "compare = 'Accu_PubxGem'\n",
    "pval1 = pub.which_stat_accuray(run=run, case=case, with_gender=with_gender, compare=compare)\n",
    "compare = 'Accu_RevxGem'\n",
    "pval2 = pub.which_stat_accuray(run=run, case=case, with_gender=with_gender, compare=compare)\n",
    "pval1, pval2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run='run01'\n",
    "verbose=True\n",
    "force=False\n",
    "\n",
    "for which in ['reviewer', 'pathway', 'accuracy']:\n",
    "    for with_gender in with_gender_list:\n",
    "        fig, df = pub.barplot_accuracy(run=run, which=which, with_gender=with_gender, \n",
    "                                       with_gender_list=with_gender_list, person_list=person_list,\n",
    "                                       run_list=run_list, case_list=case_list,\n",
    "                                       chosen_model_list=chosen_model_list,\n",
    "                                       width=1100, height=600, \n",
    "                                       fontsize=18, fontcolor='black',\n",
    "                                       margin=dict( l=20, r=20, b=100, t=120, pad=4),\n",
    "                                       plot_bgcolor=\"whitesmoke\",\n",
    "                                       minus_case=-0.15, minus_test=-0.10, minus_mnem=-0.05, \n",
    "                                       annot_fontfamily=\"Arial, monospace\", annot_fontsize=16, \n",
    "                                       annot_fontcolor='black', savePlot=True, force=force, verbose=False)\n",
    "        \n",
    "        fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run='run01'\n",
    "case=case_list[0]\n",
    "\n",
    "dfa = df_accu[(df_accu.run == run) & (df_accu.with_gender==with_gender) &  (df_accu.case == case)]\n",
    "\n",
    "row = dfa.iloc[0]\n",
    "n = row.n\n",
    "\n",
    "review_x_gemini = int(np.round(row.perc_review_x_gemini * n))\n",
    "review_x_pubmed = int(np.round(row.perc_review_x_pubmed * n))\n",
    "\n",
    "vals0 = [review_x_gemini, n-review_x_gemini]\n",
    "vals1 = [review_x_pubmed, n-review_x_pubmed]\n",
    "\n",
    "s_stat, stat, pvalue, _, _ = chi2_or_fisher_exact_test(vals0, vals1)\n",
    "print(f\"with_gender {with_gender} stats: {s_stat} - vals0 {vals0}, vals1 {vals1}\")\n",
    "print(f\"perc_review_x_gemini {100*row.perc_review_x_gemini:.1f}%, perc_review_pubmed {100*row.perc_review_x_pubmed:.1f}%\")\n",
    "print(f\"review_x_gemini {review_x_gemini}, review_x_pubmed {review_x_pubmed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Accuracy run01 without gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=['case', 'perc_pathws_crowd', 'perc_pathws_pubmed',\n",
    "      'perc_pathws_gemini', 'perc_pathws_review', 'accu_pubmed', 'accu_gemini',\n",
    "      'accu_review']\n",
    "\n",
    "df_accu[ (df_accu.run=='run01') & (df_accu.with_gender==with_gender)][cols].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_accu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df_accu[(df_accu.run == run) & (df_accu.case == case) & (df_accu.with_gender == with_gender)]\n",
    "df2.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List reviewers' files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "term = case_sel0\n",
    "files = [x for x in os.listdir(pub.root_curation) if term in x]\n",
    "print(len(files))\n",
    "print(\"\\n\".join(files[:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "term = case_sel1\n",
    "files = [x for x in os.listdir(pub.root_curation) if term in x]\n",
    "print(len(files))\n",
    "print(\"\\n\".join(files[:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gemini's answers for run, case, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose=True\n",
    "\n",
    "case=case_sel0\n",
    "run='run01'\n",
    "chosen_model=3\n",
    "query_type='_strong'\n",
    "want_pubmed=True\n",
    "\n",
    "dfgem = pub.gem.get_gemini_results_by_case_model_semantics(run=run, case=case, chosen_model=chosen_model,\n",
    "                                                           i_dfp_list=i_dfp_list, want_pubmed=want_pubmed, \n",
    "                                                           query_type=query_type, verbose=verbose)\n",
    "if dfgem is None:\n",
    "    dfgem = pd.DataFrame()\n",
    "    \n",
    "print(len(dfgem))\n",
    "dfgem.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gemini x PubMed x Reviewers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pub.pro, pub.stu, person_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reviewer x PubMed (with_gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose=True\n",
    "\n",
    "case = case_list[0]\n",
    "person = person_list[0]\n",
    "\n",
    "dfrev_pub = pub.open_pubmed_agreement(with_gender=with_gender, case=case, person=person, verbose=verbose)\n",
    "print(len(dfrev_pub))\n",
    "dfrev_pub.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gemini x Reviewers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose=True\n",
    "\n",
    "run='run01'\n",
    "case = case_list[0]\n",
    "person = person_list[0]\n",
    "\n",
    "dfrev_gem = pub.open_gemini_agreement_person(run=run, case=case, person=person, verbose=verbose)\n",
    "print(len(dfrev_gem))\n",
    "dfrev_gem.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gemini counts\n",
    " - must find 30 pathways (selected) - Ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "force=False\n",
    "verbose=True\n",
    "chosen_model=3\n",
    "run = 'run01'\n",
    "\n",
    "dfall = gem.gemini_calc_answers_counts(run=run, case_list=case_list, chosen_model=chosen_model, force=force, verbose=verbose)\n",
    "print(len(dfall))\n",
    "dfall.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case = case_sel0\n",
    "\n",
    "dfall2 = dfall[dfall.case == case]\n",
    "print(len(dfall2))\n",
    "dfall2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case = case_sel1\n",
    "\n",
    "dfall2 = dfall[dfall.case == case]\n",
    "print(len(dfall2))\n",
    "dfall2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gemini x PubMed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose=False\n",
    "\n",
    "dfc, dfg =pub.agreements_between_pubmed_and_gemini(run_list=run_list, case_list=case_list, i_dfp_list=i_dfp_list, \n",
    "                                                   chosen_model_list=chosen_model_list, with_gender_list=with_gender_list,\n",
    "                                                   force=False, verbose=verbose)\n",
    "\n",
    "print(len(dfc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc.run.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run='run01'\n",
    "\n",
    "dfc2 = dfc[  (dfc.run==run) ]\n",
    "dfc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run='run02'\n",
    "\n",
    "dfc2 = dfc[ (dfc.run==run) ]\n",
    "dfc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run='run01'\n",
    "case=case_list[0]\n",
    "\n",
    "dfn, df_both, df_only_pubmed, df_only_gemini, mu, std, n, text = \\\n",
    "    pub.open_compare_pubmed_x_gemini(run=run, case=case, i_dfp=i_dfp, \n",
    "                                     with_gender=with_gender, \n",
    "                                     chosen_model_list=chosen_model_list, verbose=True)\n",
    "\n",
    "dfn.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu =dfn.agree.mean()\n",
    "std=dfn.agree.std()\n",
    "      \n",
    "f\"with_gender {with_gender}: agree = {100*mu:.1f}% ({100*std:.1f}%)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
